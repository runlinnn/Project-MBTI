{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "D_6LVn-QZEZ8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7wIMBxvwZNiF",
    "outputId": "db6cf2a1-bfc1-4f46-deb7-0288353e862f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Length</th>\n",
       "      <th>Emoticons_count</th>\n",
       "      <th>Emoticons Avg</th>\n",
       "      <th>Unique_Words</th>\n",
       "      <th>TTR</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>Afinn Score</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>num_noun</th>\n",
       "      <th>num_adj</th>\n",
       "      <th>num_prep</th>\n",
       "      <th>num_det</th>\n",
       "      <th>num_pron</th>\n",
       "      <th>num_verb</th>\n",
       "      <th>num_adverb</th>\n",
       "      <th>num_interject</th>\n",
       "      <th>lowercase</th>\n",
       "      <th>uppercase</th>\n",
       "      <th>uppercase_num</th>\n",
       "      <th>proper cap</th>\n",
       "      <th>contractions_num</th>\n",
       "      <th>emotionalpunctuations_num</th>\n",
       "      <th>readable_num</th>\n",
       "      <th>hedge_perc</th>\n",
       "      <th>firstperson_perc</th>\n",
       "      <th>thirdperson_perc</th>\n",
       "      <th>Kincaid</th>\n",
       "      <th>ARI</th>\n",
       "      <th>Coleman-Liau</th>\n",
       "      <th>FleschReadingEase</th>\n",
       "      <th>GunningFogIndex</th>\n",
       "      <th>LIX</th>\n",
       "      <th>SMOGIndex</th>\n",
       "      <th>RIX</th>\n",
       "      <th>DaleChallIndex</th>\n",
       "      <th>characters_per_word</th>\n",
       "      <th>syll_per_word</th>\n",
       "      <th>words_per_sentence</th>\n",
       "      <th>sentences_per_paragraph</th>\n",
       "      <th>type_token_ratio</th>\n",
       "      <th>characters</th>\n",
       "      <th>syllables</th>\n",
       "      <th>words</th>\n",
       "      <th>wordtypes</th>\n",
       "      <th>sentences</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>long_words</th>\n",
       "      <th>complex_words</th>\n",
       "      <th>complex_words_dc</th>\n",
       "      <th>tobeverb</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>conjunction</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>preposition</th>\n",
       "      <th>nominalization</th>\n",
       "      <th>pronoun.1</th>\n",
       "      <th>interrogative</th>\n",
       "      <th>article</th>\n",
       "      <th>subordination</th>\n",
       "      <th>conjunction.1</th>\n",
       "      <th>preposition.1</th>\n",
       "      <th>count</th>\n",
       "      <th>E_I</th>\n",
       "      <th>N_S</th>\n",
       "      <th>F_T</th>\n",
       "      <th>J_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>disagree think theory given validity rather be...</td>\n",
       "      <td>1682</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.014863</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.007134</td>\n",
       "      <td>0.013674</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>3</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.436508</td>\n",
       "      <td>124</td>\n",
       "      <td>42</td>\n",
       "      <td>61</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>85</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>486</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>32.261518</td>\n",
       "      <td>39.660000</td>\n",
       "      <td>11.086820</td>\n",
       "      <td>3.580430</td>\n",
       "      <td>37.599575</td>\n",
       "      <td>101.642251</td>\n",
       "      <td>22.104973</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>12.927531</td>\n",
       "      <td>4.636943</td>\n",
       "      <td>1.460722</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.515924</td>\n",
       "      <td>2184</td>\n",
       "      <td>688</td>\n",
       "      <td>471</td>\n",
       "      <td>243</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>73</td>\n",
       "      <td>161</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>67</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTP</td>\n",
       "      <td>selfish generally perform task better person a...</td>\n",
       "      <td>1265</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>0.020553</td>\n",
       "      <td>0.010277</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>0.010277</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.012648</td>\n",
       "      <td>0.011858</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.009722</td>\n",
       "      <td>0.660648</td>\n",
       "      <td>73</td>\n",
       "      <td>25</td>\n",
       "      <td>46</td>\n",
       "      <td>30</td>\n",
       "      <td>53</td>\n",
       "      <td>92</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>401</td>\n",
       "      <td>0.443890</td>\n",
       "      <td>0.089776</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>38.985804</td>\n",
       "      <td>48.357195</td>\n",
       "      <td>8.449873</td>\n",
       "      <td>-5.890321</td>\n",
       "      <td>44.289526</td>\n",
       "      <td>118.205112</td>\n",
       "      <td>20.748239</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>12.389050</td>\n",
       "      <td>4.174564</td>\n",
       "      <td>1.311721</td>\n",
       "      <td>100.250000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.436409</td>\n",
       "      <td>1674</td>\n",
       "      <td>526</td>\n",
       "      <td>401</td>\n",
       "      <td>175</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>42</td>\n",
       "      <td>96</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>60</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFP</td>\n",
       "      <td>personality system technically separate  types...</td>\n",
       "      <td>738</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.033875</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>12</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.382310</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>269</td>\n",
       "      <td>0.498141</td>\n",
       "      <td>0.040892</td>\n",
       "      <td>0.048327</td>\n",
       "      <td>102.699182</td>\n",
       "      <td>131.734907</td>\n",
       "      <td>7.390028</td>\n",
       "      <td>-162.121933</td>\n",
       "      <td>110.871375</td>\n",
       "      <td>280.524164</td>\n",
       "      <td>28.690465</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>21.792209</td>\n",
       "      <td>3.962825</td>\n",
       "      <td>1.133829</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.531599</td>\n",
       "      <td>1066</td>\n",
       "      <td>305</td>\n",
       "      <td>269</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTP</td>\n",
       "      <td>like functions general theyre basically ways p...</td>\n",
       "      <td>1550</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.007097</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>10</td>\n",
       "      <td>0.108208</td>\n",
       "      <td>0.371320</td>\n",
       "      <td>80</td>\n",
       "      <td>35</td>\n",
       "      <td>55</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>82</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>389</td>\n",
       "      <td>0.519280</td>\n",
       "      <td>0.056555</td>\n",
       "      <td>0.051414</td>\n",
       "      <td>18.923333</td>\n",
       "      <td>22.510195</td>\n",
       "      <td>11.457340</td>\n",
       "      <td>36.177222</td>\n",
       "      <td>23.945475</td>\n",
       "      <td>69.142039</td>\n",
       "      <td>17.719601</td>\n",
       "      <td>11.222222</td>\n",
       "      <td>11.065275</td>\n",
       "      <td>4.752577</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>43.111111</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.536082</td>\n",
       "      <td>1844</td>\n",
       "      <td>582</td>\n",
       "      <td>388</td>\n",
       "      <td>208</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>65</td>\n",
       "      <td>130</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>even referring nihilism yeah point dying livin...</td>\n",
       "      <td>767</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.032595</td>\n",
       "      <td>0.011734</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>0.019557</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.026076</td>\n",
       "      <td>0.013038</td>\n",
       "      <td>0.019557</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>-31</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>0.518506</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3</td>\n",
       "      <td>231</td>\n",
       "      <td>0.445887</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>90.284416</td>\n",
       "      <td>114.418831</td>\n",
       "      <td>9.474105</td>\n",
       "      <td>-140.796234</td>\n",
       "      <td>96.382684</td>\n",
       "      <td>249.181818</td>\n",
       "      <td>29.267851</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>19.058689</td>\n",
       "      <td>4.320346</td>\n",
       "      <td>1.337662</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.632035</td>\n",
       "      <td>998</td>\n",
       "      <td>309</td>\n",
       "      <td>231</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>23</td>\n",
       "      <td>58</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12821</th>\n",
       "      <td>ISTP</td>\n",
       "      <td>kinda amusing deal trust relate usually someon...</td>\n",
       "      <td>599</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.040067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005008</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005008</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.006678</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.005008</td>\n",
       "      <td>6</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.594444</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>10</td>\n",
       "      <td>196</td>\n",
       "      <td>0.515306</td>\n",
       "      <td>0.137755</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>74.877551</td>\n",
       "      <td>94.352653</td>\n",
       "      <td>6.247678</td>\n",
       "      <td>-92.675408</td>\n",
       "      <td>81.053061</td>\n",
       "      <td>207.224490</td>\n",
       "      <td>22.748418</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>17.708406</td>\n",
       "      <td>3.775510</td>\n",
       "      <td>1.188776</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.668367</td>\n",
       "      <td>740</td>\n",
       "      <td>233</td>\n",
       "      <td>196</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12822</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>social 9 description fit better probably descr...</td>\n",
       "      <td>617</td>\n",
       "      <td>23</td>\n",
       "      <td>0.037277</td>\n",
       "      <td>25</td>\n",
       "      <td>0.040519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.011345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>8</td>\n",
       "      <td>0.072549</td>\n",
       "      <td>0.548039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>E</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12823</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>believe blood type influence someone personali...</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.011538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>8</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>25.853529</td>\n",
       "      <td>33.072353</td>\n",
       "      <td>9.358734</td>\n",
       "      <td>30.820882</td>\n",
       "      <td>29.552941</td>\n",
       "      <td>81.235294</td>\n",
       "      <td>13.954451</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.511065</td>\n",
       "      <td>4.352941</td>\n",
       "      <td>1.264706</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>296</td>\n",
       "      <td>86</td>\n",
       "      <td>68</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12824</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>benevolent creator linkpractical 26 conceptual...</td>\n",
       "      <td>645</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>25</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.013953</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>25</td>\n",
       "      <td>0.171930</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>315</td>\n",
       "      <td>131</td>\n",
       "      <td>159</td>\n",
       "      <td>134</td>\n",
       "      <td>223</td>\n",
       "      <td>324</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>62</td>\n",
       "      <td>1590</td>\n",
       "      <td>0.515094</td>\n",
       "      <td>0.105031</td>\n",
       "      <td>0.045283</td>\n",
       "      <td>624.122991</td>\n",
       "      <td>799.551981</td>\n",
       "      <td>7.253224</td>\n",
       "      <td>-1520.913645</td>\n",
       "      <td>644.317757</td>\n",
       "      <td>1618.084112</td>\n",
       "      <td>55.820451</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>86.835372</td>\n",
       "      <td>3.923988</td>\n",
       "      <td>1.166355</td>\n",
       "      <td>1605.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.398131</td>\n",
       "      <td>6298</td>\n",
       "      <td>1872</td>\n",
       "      <td>1605</td>\n",
       "      <td>639</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>93</td>\n",
       "      <td>365</td>\n",
       "      <td>55</td>\n",
       "      <td>24</td>\n",
       "      <td>53</td>\n",
       "      <td>271</td>\n",
       "      <td>164</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12825</th>\n",
       "      <td>INFP</td>\n",
       "      <td>traveled alone found part rather painful part ...</td>\n",
       "      <td>571</td>\n",
       "      <td>22</td>\n",
       "      <td>0.038529</td>\n",
       "      <td>26</td>\n",
       "      <td>0.045534</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.007005</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>0.017513</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>4</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.698810</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12826 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Tag                                       Cleaned_Text  ...  F_T  J_P\n",
       "0      ENFP  disagree think theory given validity rather be...  ...    F    P\n",
       "1      INTP  selfish generally perform task better person a...  ...    T    P\n",
       "2      INFP  personality system technically separate  types...  ...    F    P\n",
       "3      INTP  like functions general theyre basically ways p...  ...    T    P\n",
       "4      ENTP  even referring nihilism yeah point dying livin...  ...    T    P\n",
       "...     ...                                                ...  ...  ...  ...\n",
       "12821  ISTP  kinda amusing deal trust relate usually someon...  ...    T    P\n",
       "12822  ESFP  social 9 description fit better probably descr...  ...    F    P\n",
       "12823  ISFP  believe blood type influence someone personali...  ...    F    P\n",
       "12824  INFJ  benevolent creator linkpractical 26 conceptual...  ...    F    J\n",
       "12825  INFP  traveled alone found part rather painful part ...  ...    F    P\n",
       "\n",
       "[12826 rows x 78 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('combined_with_split_tags.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhzv-EEOZPLM",
    "outputId": "2a815a65-a0f4-48f6-93e0-82c9253d71b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "12821    0\n",
       "12822    1\n",
       "12823    1\n",
       "12824    1\n",
       "12825    1\n",
       "Name: FT, Length: 12826, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FT'] = df['Tag'].apply(lambda x: 1 if 'F' in x else 0)\n",
    "df['FT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2gpjvMQ-aBeX"
   },
   "outputs": [],
   "source": [
    "# # Parameters for RandomizedSearchCV\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "# Another set of paramters, if you want to try\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100],\n",
    "    'min_samples_leaf': [3, 4],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [200, 300],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CXx_SVYNaDBV"
   },
   "outputs": [],
   "source": [
    "FT_allfeatures = df.drop(columns = ['Tag', 'FT','E_I',\t'N_S',\t'F_T',\t'J_P'])\n",
    "FT_y = df['FT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(FT_allfeatures, FT_y, test_size=0.2, random_state=1)\n",
    "y_train = y_train.reset_index(drop = True)\n",
    "y_test = y_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xkvLr55iaG1a"
   },
   "outputs": [],
   "source": [
    "X_train_cleanedtext = X_train['Cleaned_Text']\n",
    "X_train_features = X_train.drop(columns = ['Cleaned_Text'])\n",
    "X_train_features = X_train_features.reset_index(drop = True)\n",
    "\n",
    "X_test_cleanedtext = X_test['Cleaned_Text']\n",
    "X_test_features = X_test.drop(columns = ['Cleaned_Text'])\n",
    "X_test_features = X_test_features.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rBk5kypZaI0i"
   },
   "outputs": [],
   "source": [
    "# Word Representation\n",
    "\n",
    "vect = CountVectorizer(max_features = 5000)\n",
    "X_train_dtm = vect.fit_transform(X_train_cleanedtext)\n",
    "X_test_dtm = vect.transform(X_test_cleanedtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "g-h-5HLZaKIS"
   },
   "outputs": [],
   "source": [
    "X_train_dtm_df = pd.DataFrame(X_train_dtm.toarray(), columns = vect.get_feature_names())\n",
    "X_test_dtm_df = pd.DataFrame(X_test_dtm.toarray(), columns = vect.get_feature_names())\n",
    "\n",
    "X_train_allfeatures = pd.concat([X_train_dtm_df, X_train_features], axis=1)\n",
    "X_test_allfeatures = pd.concat([X_test_dtm_df, X_test_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uCNQV9tWmHcc"
   },
   "outputs": [],
   "source": [
    "# X_train_allfeatures.isna()\n",
    "# X_train_allfeatures[X_train_allfeatures.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PaekDndDlge7",
    "outputId": "ac6c8e20-682b-443c-9c2a-130c4371da82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 35.9min\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed: 49.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True],\n",
       "                         'class_weight': ['balanced', 'balanced_subsample'],\n",
       "                         'max_depth': [80, 90, 100], 'min_samples_leaf': [3, 4],\n",
       "                         'min_samples_split': [8, 10, 12],\n",
       "                         'n_estimators': [200, 300]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train_allfeatures,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s2pnRV2WlrGC",
    "outputId": "a09d393c-a8ac-4700-f9bd-83f90b1047c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'class_weight': 'balanced', 'max_depth': 80, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 300}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid_search.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foM-OV8uZj5D",
    "outputId": "7176737c-5dbe-4801-a404-ffa4e8eefe45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6769290724863601"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting on the transformed data\n",
    "grid_predictions = grid_search.predict(X_test_allfeatures)\n",
    "\n",
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, grid_predictions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yDWFtt2MVwHZ"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(grid_search, open(\"model_ft.sav\", \"wb\"))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
