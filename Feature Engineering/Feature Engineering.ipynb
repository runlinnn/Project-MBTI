{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering (Emotion, Formality (POS), Number of Unique Token, Length of each post); Basic TF IDF vectoriser + Cosine Similarity - Valli & Run Lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from afinn import Afinn\n",
    "from textblob import TextBlob\n",
    "\n",
    "# check which is used\n",
    "import spacy, collections, readability\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ne_chunk, pos_tag, ngrams\n",
    "from pickle import dump, load\n",
    "from nltk.parse import CoreNLPParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Cleaned_Text_No_Emoticon</th>\n",
       "      <th>Text_stemmed</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Reddit</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Typology</th>\n",
       "      <th>Kaggle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>memeincorrect quote sure trying keep peace family</td>\n",
       "      <td>memeincorrect quote sure trying keep peace family</td>\n",
       "      <td>memeincorrect quot sure tri peac famili</td>\n",
       "      <td>memeincorrect quote sure trying keep_peace family</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>memefour distinct flavors nt</td>\n",
       "      <td>memefour distinct flavors nt</td>\n",
       "      <td>memefour distinct flavor</td>\n",
       "      <td>memefour distinct flavors nt</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>memethis definitely intp looks like</td>\n",
       "      <td>memethis definitely intp looks like</td>\n",
       "      <td>memethi definit intp look like</td>\n",
       "      <td>memethis definitely intp looks_like</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>theory questionwhat type admire</td>\n",
       "      <td>theory questionwhat type admire</td>\n",
       "      <td>theori questionwhat type admir</td>\n",
       "      <td>theory_questionwhat type admire</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>memeistj x enfp real</td>\n",
       "      <td>memeistj x enfp real</td>\n",
       "      <td>memeistj enfp real</td>\n",
       "      <td>memeistj x enfp real</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134164</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>always think cats fi doms reason websites beco...</td>\n",
       "      <td>always think cats fi doms reason websites beco...</td>\n",
       "      <td>think cat dom reason websit nazi perci nerd le...</td>\n",
       "      <td>always think cats fi_doms reason websites beco...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134165</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>soif thread already exists someplace else heck...</td>\n",
       "      <td>soif thread already exists someplace else heck...</td>\n",
       "      <td>soif thread exist someplac heck delet hereooop...</td>\n",
       "      <td>soif thread already_exists someplace else heck...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134166</th>\n",
       "      <td>INTP</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>question thing purpl pill pick win lotteri num...</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134167</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>conflict right come want children honest mater...</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134168</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>long personalitycaf chang good like usual turn...</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134169 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag                                       Cleaned_Text  \\\n",
       "0       ENFJ  memeincorrect quote sure trying keep peace family   \n",
       "1       ENTP                       memefour distinct flavors nt   \n",
       "2       ENTP                memethis definitely intp looks like   \n",
       "3       ISFJ                    theory questionwhat type admire   \n",
       "4       ISTJ                               memeistj x enfp real   \n",
       "...      ...                                                ...   \n",
       "134164  ISFP  always think cats fi doms reason websites beco...   \n",
       "134165  ENFP  soif thread already exists someplace else heck...   \n",
       "134166  INTP  many questions things would take purple pill p...   \n",
       "134167  INFP  conflicted right comes wanting children honest...   \n",
       "134168  INFP  long since personalitycafe although seem chang...   \n",
       "\n",
       "                                 Cleaned_Text_No_Emoticon  \\\n",
       "0       memeincorrect quote sure trying keep peace family   \n",
       "1                            memefour distinct flavors nt   \n",
       "2                     memethis definitely intp looks like   \n",
       "3                         theory questionwhat type admire   \n",
       "4                                    memeistj x enfp real   \n",
       "...                                                   ...   \n",
       "134164  always think cats fi doms reason websites beco...   \n",
       "134165  soif thread already exists someplace else heck...   \n",
       "134166  many questions things would take purple pill p...   \n",
       "134167  conflicted right comes wanting children honest...   \n",
       "134168  long since personalitycafe although seem chang...   \n",
       "\n",
       "                                             Text_stemmed  \\\n",
       "0                 memeincorrect quot sure tri peac famili   \n",
       "1                                memefour distinct flavor   \n",
       "2                          memethi definit intp look like   \n",
       "3                          theori questionwhat type admir   \n",
       "4                                      memeistj enfp real   \n",
       "...                                                   ...   \n",
       "134164  think cat dom reason websit nazi perci nerd le...   \n",
       "134165  soif thread exist someplac heck delet hereooop...   \n",
       "134166  question thing purpl pill pick win lotteri num...   \n",
       "134167  conflict right come want children honest mater...   \n",
       "134168  long personalitycaf chang good like usual turn...   \n",
       "\n",
       "                                                   Bigram  Reddit  Twitter  \\\n",
       "0       memeincorrect quote sure trying keep_peace family       1        0   \n",
       "1                            memefour distinct flavors nt       1        0   \n",
       "2                     memethis definitely intp looks_like       1        0   \n",
       "3                         theory_questionwhat type admire       1        0   \n",
       "4                                    memeistj x enfp real       1        0   \n",
       "...                                                   ...     ...      ...   \n",
       "134164  always think cats fi_doms reason websites beco...       0        0   \n",
       "134165  soif thread already_exists someplace else heck...       0        0   \n",
       "134166  many questions things would take purple pill p...       0        0   \n",
       "134167  conflicted right comes wanting children honest...       0        0   \n",
       "134168  long since personalitycafe although seem chang...       0        0   \n",
       "\n",
       "        Typology  Kaggle  \n",
       "0              0       0  \n",
       "1              0       0  \n",
       "2              0       0  \n",
       "3              0       0  \n",
       "4              0       0  \n",
       "...          ...     ...  \n",
       "134164         0       1  \n",
       "134165         0       1  \n",
       "134166         0       1  \n",
       "134167         0       1  \n",
       "134168         0       1  \n",
       "\n",
       "[134169 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('MBTI.csv')\n",
    "df = df.drop(columns = ['Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def polarity(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "def subjectivity(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.subjectivity\n",
    "\n",
    "polarity('Just get out, please. I hate it here.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-e768e1fbfb73>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_df['Afinn Score'] = [afinn.score(text) for text in df.Cleaned_Text]\n",
      "<ipython-input-228-e768e1fbfb73>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_df['Polarity'] = [polarity(text) for text in df.Cleaned_Text]\n",
      "<ipython-input-228-e768e1fbfb73>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_df['Subjectivity'] = [subjectivity(text) for text in df.Cleaned_Text]\n",
      "<ipython-input-228-e768e1fbfb73>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_df['Length'] = [len(text) for text in df.Cleaned_Text]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Afinn Score</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>memeincorrect quote sure trying keep peace family</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>memefour distinct flavors nt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>memethis definitely intp looks like</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>theory questionwhat type admire</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>memeistj x enfp real</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134164</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>always think cats fi doms reason websites beco...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.139790</td>\n",
       "      <td>0.579605</td>\n",
       "      <td>2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134165</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>soif thread already exists someplace else heck...</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.201315</td>\n",
       "      <td>0.563804</td>\n",
       "      <td>4496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134166</th>\n",
       "      <td>INTP</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.101508</td>\n",
       "      <td>0.535257</td>\n",
       "      <td>3469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134167</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.095494</td>\n",
       "      <td>0.558648</td>\n",
       "      <td>5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134168</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.234718</td>\n",
       "      <td>0.477302</td>\n",
       "      <td>4112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134169 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag                                       Cleaned_Text  Afinn Score  \\\n",
       "0       ENFJ  memeincorrect quote sure trying keep peace family          2.0   \n",
       "1       ENTP                       memefour distinct flavors nt          0.0   \n",
       "2       ENTP                memethis definitely intp looks like          2.0   \n",
       "3       ISFJ                    theory questionwhat type admire          3.0   \n",
       "4       ISTJ                               memeistj x enfp real          0.0   \n",
       "...      ...                                                ...          ...   \n",
       "134164  ISFP  always think cats fi doms reason websites beco...         23.0   \n",
       "134165  ENFP  soif thread already exists someplace else heck...        144.0   \n",
       "134166  INTP  many questions things would take purple pill p...         11.0   \n",
       "134167  INFP  conflicted right comes wanting children honest...         54.0   \n",
       "134168  INFP  long since personalitycafe although seem chang...        118.0   \n",
       "\n",
       "        Polarity  Subjectivity  Length  \n",
       "0       0.500000      0.888889      49  \n",
       "1       0.300000      0.300000      28  \n",
       "2       0.000000      0.500000      35  \n",
       "3       0.000000      0.000000      31  \n",
       "4       0.200000      0.300000      20  \n",
       "...          ...           ...     ...  \n",
       "134164  0.139790      0.579605    2859  \n",
       "134165  0.201315      0.563804    4496  \n",
       "134166  0.101508      0.535257    3469  \n",
       "134167  0.095494      0.558648    5423  \n",
       "134168  0.234718      0.477302    4112  \n",
       "\n",
       "[134169 rows x 6 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = df[['Tag', 'Cleaned_Text']]\n",
    "\n",
    "afinn = Afinn(emoticons=True)\n",
    "features_df['Afinn Score'] = [afinn.score(text) for text in df.Cleaned_Text]\n",
    "features_df['Polarity'] = [polarity(text) for text in df.Cleaned_Text]\n",
    "features_df['Subjectivity'] = [subjectivity(text) for text in df.Cleaned_Text]\n",
    "features_df['Length'] = [len(text) for text in df.Cleaned_Text]\n",
    "\n",
    "    \n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv(r'C:\\Users\\School\\Desktop\\4222\\Project MBTI\\Basic Features on Cleaned Data.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Text</th>\n",
       "      <th>Reddit</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Typology</th>\n",
       "      <th>Kaggle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Meme&lt;3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>MemeIncorrect Quote? Not so sure. Just me, try...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>MemeENFP Avatar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>MemeFour Distinct Flavors of NT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>StereotypesINFP </td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214114</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>https://www.youtube.com/watch?v=t8edHB_h908|||...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214115</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214116</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214117</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214118</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214119 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag                                               Text  Reddit  \\\n",
       "0       INFP                                            Meme<3        1   \n",
       "1       ENFJ  MemeIncorrect Quote? Not so sure. Just me, try...       1   \n",
       "2       INTP                                   MemeENFP Avatar        1   \n",
       "3       ENTP                   MemeFour Distinct Flavors of NT        1   \n",
       "4       INTJ                                 StereotypesINFP         1   \n",
       "...      ...                                                ...     ...   \n",
       "214114  ISFP  https://www.youtube.com/watch?v=t8edHB_h908|||...       0   \n",
       "214115  ENFP  'So...if this thread already exists someplace ...       0   \n",
       "214116  INTP  'So many questions when i do these things.  I ...       0   \n",
       "214117  INFP  'I am very conflicted right now when it comes ...       0   \n",
       "214118  INFP  'It has been too long since I have been on per...       0   \n",
       "\n",
       "        Twitter  Typology  Kaggle  \n",
       "0             0         0       0  \n",
       "1             0         0       0  \n",
       "2             0         0       0  \n",
       "3             0         0       0  \n",
       "4             0         0       0  \n",
       "...         ...       ...     ...  \n",
       "214114        0         0       1  \n",
       "214115        0         0       1  \n",
       "214116        0         0       1  \n",
       "214117        0         0       1  \n",
       "214118        0         0       1  \n",
       "\n",
       "[214119 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_excel('BT4222_Combined_dataset_Version 2.xlsx')\n",
    "raw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic cleaning \n",
    "raw_df['Text'] = [str(text).replace(':', '',) for text in raw_df.Text]\n",
    "raw_df['Text'] = [str(text).replace('/', '',) for text in raw_df.Text]\n",
    "raw_df = raw_df[raw_df['Text']!= \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic analysis\n",
    "afinn = Afinn(emoticons=True)\n",
    "raw_df['Afinn Score'] = [afinn.score(text) for text in raw_df.Text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-14adb08c6a20>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['Polarity'] = [polarity(text) for text in raw_df.Text]\n",
      "<ipython-input-6-14adb08c6a20>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['Subjectivity'] = [subjectivity(text) for text in raw_df.Text]\n",
      "<ipython-input-6-14adb08c6a20>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['Length'] = [len(text) for text in raw_df.Text]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Text</th>\n",
       "      <th>Reddit</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Typology</th>\n",
       "      <th>Kaggle</th>\n",
       "      <th>Afinn Score</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Meme&lt;3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>MemeIncorrect Quote? Not so sure. Just me, try...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>MemeENFP Avatar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>MemeFour Distinct Flavors of NT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>StereotypesINFP </td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214114</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>httpswww.youtube.comwatch?v=t8edHB_h908|||IxFP...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.136994</td>\n",
       "      <td>0.575641</td>\n",
       "      <td>4960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214115</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.202983</td>\n",
       "      <td>0.550482</td>\n",
       "      <td>7843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214116</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.105284</td>\n",
       "      <td>0.522723</td>\n",
       "      <td>5752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214117</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.117591</td>\n",
       "      <td>0.543356</td>\n",
       "      <td>9470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214118</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.157998</td>\n",
       "      <td>0.453756</td>\n",
       "      <td>7397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212138 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag                                               Text  Reddit  \\\n",
       "0       INFP                                            Meme<3        1   \n",
       "1       ENFJ  MemeIncorrect Quote? Not so sure. Just me, try...       1   \n",
       "2       INTP                                   MemeENFP Avatar        1   \n",
       "3       ENTP                   MemeFour Distinct Flavors of NT        1   \n",
       "4       INTJ                                 StereotypesINFP         1   \n",
       "...      ...                                                ...     ...   \n",
       "214114  ISFP  httpswww.youtube.comwatch?v=t8edHB_h908|||IxFP...       0   \n",
       "214115  ENFP  'So...if this thread already exists someplace ...       0   \n",
       "214116  INTP  'So many questions when i do these things.  I ...       0   \n",
       "214117  INFP  'I am very conflicted right now when it comes ...       0   \n",
       "214118  INFP  'It has been too long since I have been on per...       0   \n",
       "\n",
       "        Twitter  Typology  Kaggle  Afinn Score  Polarity  Subjectivity  Length  \n",
       "0             0         0       0          3.0  0.000000      0.000000       7  \n",
       "1             0         0       0          2.0  0.500000      0.888889      83  \n",
       "2             0         0       0          0.0  0.000000      0.000000      16  \n",
       "3             0         0       0          0.0  0.300000      0.300000      32  \n",
       "4             0         0       0          0.0  0.000000      0.000000      18  \n",
       "...         ...       ...     ...          ...       ...           ...     ...  \n",
       "214114        0         0       1         21.0  0.136994      0.575641    4960  \n",
       "214115        0         0       1        176.0  0.202983      0.550482    7843  \n",
       "214116        0         0       1         21.0  0.105284      0.522723    5752  \n",
       "214117        0         0       1         60.0  0.117591      0.543356    9470  \n",
       "214118        0         0       1        108.0  0.157998      0.453756    7397  \n",
       "\n",
       "[212138 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Polarity'] = [polarity(text) for text in raw_df.Text]\n",
    "raw_df['Subjectivity'] = [subjectivity(text) for text in raw_df.Text]\n",
    "raw_df['Length'] = [len(text) for text in raw_df.Text]\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize,sent_tokenize,ne_chunk\n",
    "\n",
    "\n",
    "def split_tokens(text):\n",
    "    ''' Split text into tokens.'''\n",
    "    text = text.replace('/',' ')\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens\n",
    "    \n",
    "def POS_tagging(text):\n",
    "    ''' Generate Part of speech tagging of the text. '''\n",
    "    POSofText = nltk.tag.pos_tag(text)\n",
    "    return POSofText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-5c23af6915aa>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['num_noun'] = num_noun\n",
      "<ipython-input-8-5c23af6915aa>:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['num_adj'] = num_adj\n",
      "<ipython-input-8-5c23af6915aa>:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['num_prep'] = num_prep\n",
      "<ipython-input-8-5c23af6915aa>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['num_det'] = num_det\n",
      "<ipython-input-8-5c23af6915aa>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['num_pron'] = num_pron\n",
      "<ipython-input-8-5c23af6915aa>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['num_verb'] = num_verb\n",
      "<ipython-input-8-5c23af6915aa>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['num_adverb'] = num_adverb\n",
      "<ipython-input-8-5c23af6915aa>:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['num_interject'] = num_interject\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Text</th>\n",
       "      <th>Reddit</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Typology</th>\n",
       "      <th>Kaggle</th>\n",
       "      <th>Afinn Score</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Length</th>\n",
       "      <th>num_noun</th>\n",
       "      <th>num_adj</th>\n",
       "      <th>num_prep</th>\n",
       "      <th>num_det</th>\n",
       "      <th>num_pron</th>\n",
       "      <th>num_verb</th>\n",
       "      <th>num_adverb</th>\n",
       "      <th>num_interject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Meme&lt;3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>MemeIncorrect Quote? Not so sure. Just me, try...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>MemeENFP Avatar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>MemeFour Distinct Flavors of NT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>StereotypesINFP </td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214114</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>httpswww.youtube.comwatch?v=t8edHB_h908|||IxFP...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.136994</td>\n",
       "      <td>0.575641</td>\n",
       "      <td>4960</td>\n",
       "      <td>191</td>\n",
       "      <td>74</td>\n",
       "      <td>93</td>\n",
       "      <td>69</td>\n",
       "      <td>95</td>\n",
       "      <td>185</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214115</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.202983</td>\n",
       "      <td>0.550482</td>\n",
       "      <td>7843</td>\n",
       "      <td>314</td>\n",
       "      <td>91</td>\n",
       "      <td>116</td>\n",
       "      <td>91</td>\n",
       "      <td>201</td>\n",
       "      <td>329</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214116</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.105284</td>\n",
       "      <td>0.522723</td>\n",
       "      <td>5752</td>\n",
       "      <td>256</td>\n",
       "      <td>69</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>125</td>\n",
       "      <td>210</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214117</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.117591</td>\n",
       "      <td>0.543356</td>\n",
       "      <td>9470</td>\n",
       "      <td>323</td>\n",
       "      <td>113</td>\n",
       "      <td>218</td>\n",
       "      <td>137</td>\n",
       "      <td>253</td>\n",
       "      <td>398</td>\n",
       "      <td>183</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214118</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.157998</td>\n",
       "      <td>0.453756</td>\n",
       "      <td>7397</td>\n",
       "      <td>249</td>\n",
       "      <td>92</td>\n",
       "      <td>116</td>\n",
       "      <td>97</td>\n",
       "      <td>210</td>\n",
       "      <td>325</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212138 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag                                               Text  Reddit  \\\n",
       "0       INFP                                            Meme<3        1   \n",
       "1       ENFJ  MemeIncorrect Quote? Not so sure. Just me, try...       1   \n",
       "2       INTP                                   MemeENFP Avatar        1   \n",
       "3       ENTP                   MemeFour Distinct Flavors of NT        1   \n",
       "4       INTJ                                 StereotypesINFP         1   \n",
       "...      ...                                                ...     ...   \n",
       "214114  ISFP  httpswww.youtube.comwatch?v=t8edHB_h908|||IxFP...       0   \n",
       "214115  ENFP  'So...if this thread already exists someplace ...       0   \n",
       "214116  INTP  'So many questions when i do these things.  I ...       0   \n",
       "214117  INFP  'I am very conflicted right now when it comes ...       0   \n",
       "214118  INFP  'It has been too long since I have been on per...       0   \n",
       "\n",
       "        Twitter  Typology  Kaggle  Afinn Score  Polarity  Subjectivity  \\\n",
       "0             0         0       0          3.0  0.000000      0.000000   \n",
       "1             0         0       0          2.0  0.500000      0.888889   \n",
       "2             0         0       0          0.0  0.000000      0.000000   \n",
       "3             0         0       0          0.0  0.300000      0.300000   \n",
       "4             0         0       0          0.0  0.000000      0.000000   \n",
       "...         ...       ...     ...          ...       ...           ...   \n",
       "214114        0         0       1         21.0  0.136994      0.575641   \n",
       "214115        0         0       1        176.0  0.202983      0.550482   \n",
       "214116        0         0       1         21.0  0.105284      0.522723   \n",
       "214117        0         0       1         60.0  0.117591      0.543356   \n",
       "214118        0         0       1        108.0  0.157998      0.453756   \n",
       "\n",
       "        Length  num_noun  num_adj  num_prep  num_det  num_pron  num_verb  \\\n",
       "0            7         1        0         0        0         0         1   \n",
       "1           83         6        1         1        1         2         2   \n",
       "2           16         2        0         0        0         0         0   \n",
       "3           32         4        0         1        0         0         0   \n",
       "4           18         2        0         0        0         0         0   \n",
       "...        ...       ...      ...       ...      ...       ...       ...   \n",
       "214114    4960       191       74        93       69        95       185   \n",
       "214115    7843       314       91       116       91       201       329   \n",
       "214116    5752       256       69        88       80       125       210   \n",
       "214117    9470       323      113       218      137       253       398   \n",
       "214118    7397       249       92       116       97       210       325   \n",
       "\n",
       "        num_adverb  num_interject  \n",
       "0                0              0  \n",
       "1                2              0  \n",
       "2                0              0  \n",
       "3                0              0  \n",
       "4                0              0  \n",
       "...            ...            ...  \n",
       "214114          64              1  \n",
       "214115         112              0  \n",
       "214116          61              1  \n",
       "214117         183              3  \n",
       "214118         140              0  \n",
       "\n",
       "[212138 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#should be done without stop words cleaned\n",
    "\n",
    "noun = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "adj = ['JJ', 'JJR', 'JJS']\n",
    "prep = ['IN']\n",
    "det = ['DT']\n",
    "pron = ['PRP', 'PRP$', 'WP', 'WP$']\n",
    "verb = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "adverb = ['RB', 'RBR', 'RBS']\n",
    "interject = ['UH']\n",
    "\n",
    "#grammar = [noun, adj, prep, pron, verb, adverb, interject]\n",
    "#formality = 0.5(freq_noun + freq_adj + freq_prep + freq_article) - 0.5(freq_pron + freq_verb + freq_adverb + freq_interjection) + 50\n",
    "\n",
    "num_noun, num_adj, num_prep, num_det, num_pron, num_verb, num_adverb, num_interject = [],[],[],[],[],[],[],[]\n",
    "\n",
    "for index, row in raw_df.iterrows():\n",
    "    count_noun, count_adj, count_prep, count_det, count_pron, count_verb, count_adverb, count_interject = 0,0,0,0,0,0,0,0\n",
    "    text = row['Text']\n",
    "    tokens = split_tokens(text)\n",
    "    postags = POS_tagging(tokens)\n",
    "    \n",
    "    for word in postags:\n",
    "        if word[1] in noun:\n",
    "            count_noun += 1\n",
    "        if word[1] in adj:\n",
    "            count_adj += 1\n",
    "        if word[1] in prep:\n",
    "            count_prep += 1\n",
    "        if word[1] in det:\n",
    "            count_det += 1\n",
    "        if word[1] in pron:\n",
    "            count_pron += 1\n",
    "        if word[1] in verb:\n",
    "            count_verb += 1\n",
    "        if word[1] in adverb:\n",
    "            count_adverb += 1\n",
    "        if word[1] in interject:\n",
    "            count_interject += 1\n",
    "\n",
    "    num_noun.append(count_noun)\n",
    "    num_adj.append(count_adj)\n",
    "    num_prep.append(count_prep)\n",
    "    num_det.append(count_det)\n",
    "    num_pron.append(count_pron)\n",
    "    num_verb.append(count_verb)\n",
    "    num_adverb.append(count_adverb)\n",
    "    num_interject.append(count_interject)\n",
    "    \n",
    "raw_df['num_noun'] = num_noun\n",
    "raw_df['num_adj'] = num_adj\n",
    "raw_df['num_prep'] = num_prep\n",
    "raw_df['num_det'] = num_det\n",
    "raw_df['num_pron'] = num_pron\n",
    "raw_df['num_verb'] = num_verb\n",
    "raw_df['num_adverb'] = num_adverb\n",
    "raw_df['num_interject'] = num_interject\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_lowercase(string):\n",
    "    \"\"\"\n",
    "    binary indicator for whether sentence is all in lowercase;\n",
    "    1 for true, 0 for false\n",
    "    \"\"\"\n",
    "    return int(string.islower())\n",
    "\n",
    "def get_all_uppercase(string):\n",
    "    \"\"\"\n",
    "    binary indicator for whether sentence is all in lowercase;\n",
    "    1 for true, 0 for false\n",
    "    \"\"\"\n",
    "    return int(string.isupper())\n",
    "\n",
    "def get_uppercase_num(string):\n",
    "    \"\"\"\n",
    "    return number of words in ALL CAPS\n",
    "    \"\"\"\n",
    "    return len([w for w in word_tokenize(string) if w.isupper()])\n",
    "\n",
    "def get_case(string):\n",
    "    \"\"\"\n",
    "    binary indicator for whether the first word is capitalized.\n",
    "    \"\"\"\n",
    "    return int(string[0].isupper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_contractions(string):\n",
    "    \"\"\"\n",
    "    return the number of contractions in the sentence, normalized by length\n",
    "    \"\"\"\n",
    "    # prepare\n",
    "\n",
    "    tokens = word_tokenize(string.lower())\n",
    "    length = len(tokens)\n",
    "    if length == 0:\n",
    "        return 0\n",
    "\n",
    "    # 1. number of contractions, norm by length\n",
    "    cont_count = 0\n",
    "    for w in tokens:\n",
    "        if \"\\'\" in w and len(w) > 1:\n",
    "            cont_count += 1\n",
    "    return round(cont_count/length, 2)\n",
    "\n",
    "get_contractions(\"My name's Barack Obama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_punctuation_number(string):\n",
    "    \"\"\"\n",
    "    punctuation Number of ?, ..., and ! in the sentence.\n",
    "    \"\"\"\n",
    "    punct_number = 0\n",
    "    tokens = word_tokenize(string)\n",
    "\n",
    "    for w in tokens:\n",
    "        if w in [\"?\", \"...\", \"!\"]:\n",
    "            punct_number += 1\n",
    "    return punct_number\n",
    "\n",
    "get_punctuation_number(\"Why are you calling me?!! AFHKSHFERGOF ERHEK894G4WE\" ) #AFHKSHFERGOF readable, ERHEK894G4WE unreadable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_readable_words(text):\n",
    "    \"\"\"\n",
    "    return readability Length of the sentence, in words and characters; Flesch-Kincaid Grade Level score.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        blob = TextBlob(text)\n",
    "        results = readability.getmeasures(text, lang='en')\n",
    "        return len(blob.words)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    \n",
    "get_readable_words(\"Why are you calling me? AFHKSHFERGOF ERHEK894G4WE\" ) #AFHKSHFERGOF readable, ERHEK894G4WE unreadable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HEDGE_WORDS = \"largely generally often rarely sometimes frequently occasionally seldom usually most several some almost practically apparently virtually basically approximately roughly somewhat somehow partially actually like something someone somebody somewhere think thinks thought believe believed believes consider considers considered assume assumes assumed understand understands understood find found finds appear appears appeared seem seems seemed suppose supposes supposed guess guesses guessed estimate estimates estimated speculate speculates speculated suggest suggests suggested may could should might surely probably likely maybe perhaps unsure probable unlikely possibly possible read say says looks like look like don't know necessarily kind of much bunch couple few little really and all that and so forth et cetera in my mind in my opinion their impression my impression in my understanding my thinking is my understanding is in my view if i'm understanding you correctly something or other so far at least  about around can effectively evidently fairly hopefully in general mainly more or less mostly overall presumably  pretty quite clearly quite rather sort of supposedly  tend appear to be doubt be sure indicate will must would certainly definitely clearly conceivably certain definite clear assumption possibility probability  many almost never improbable always rare consistent with doubtful suggestive diagnostic inconclusive apparent alleged allege a bit presumable\".split()\n",
    "FIRST_PERSON_PRONOUNS = ['I', 'me', 'my', 'mine', 'we', 'us', 'our', 'ours', 'my', 'mine', 'our', 'ours']\n",
    "THIRD_PERSON_PRONOUNS = ['he', 'she', 'it', 'one', 'they', 'him', 'her', 'it', 'one', 'them', 'his', 'hers', 'theirs',\n",
    "                         'himself', 'herself', 'itself', 'oneself', 'themselves']\n",
    "\n",
    "def get_count(pronouns, blob):\n",
    "    count = 0\n",
    "    for pronoun in pronouns:\n",
    "        count += blob.words.count(pronoun)\n",
    "    return count\n",
    "\n",
    "def get_hedge(text):\n",
    "    blob = TextBlob(text)\n",
    "    length = len(blob.words)\n",
    "    if length == 0:\n",
    "        return 0\n",
    "    return get_count(HEDGE_WORDS, blob) / length\n",
    "\n",
    "def get_firstperson(text):\n",
    "    blob = TextBlob(text)\n",
    "    length = len(blob.words)\n",
    "    if length == 0:\n",
    "        return 0\n",
    "    return get_count(FIRST_PERSON_PRONOUNS, blob) / length\n",
    "\n",
    "def get_thirdperson(text):\n",
    "    blob = TextBlob(text)\n",
    "    length = len(blob.words)\n",
    "    if length == 0:\n",
    "        return 0\n",
    "    return get_count(THIRD_PERSON_PRONOUNS, blob) / length\n",
    "\n",
    "get_hedge(\"It is proven to be largely true.\")\n",
    "get_firstperson(\"I don't like that\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-db376faa7ab4>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['lowercase'] = [get_all_lowercase(text) for text in raw_df.Text]\n",
      "<ipython-input-14-db376faa7ab4>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['uppercase'] = [get_all_uppercase(text) for text in raw_df.Text]\n",
      "<ipython-input-14-db376faa7ab4>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['uppercase_num'] = [get_uppercase_num(text) for text in raw_df.Text]\n",
      "<ipython-input-14-db376faa7ab4>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['proper cap'] = [get_case(text) for text in raw_df.Text]\n"
     ]
    }
   ],
   "source": [
    "raw_df['lowercase'] = [get_all_lowercase(text) for text in raw_df.Text]\n",
    "raw_df['uppercase'] = [get_all_uppercase(text) for text in raw_df.Text]\n",
    "raw_df['uppercase_num'] = [get_uppercase_num(text) for text in raw_df.Text]\n",
    "raw_df['proper cap'] = [get_case(text) for text in raw_df.Text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-4f0c37e1f7cf>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['contractions_num'] = [get_contractions(text) for text in raw_df.Text]\n",
      "<ipython-input-15-4f0c37e1f7cf>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['emotionalpunctuations_num'] = [get_punctuation_number(text) for text in raw_df.Text]\n",
      "<ipython-input-15-4f0c37e1f7cf>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['readable_num'] = [get_readable_words(text) for text in raw_df.Text]\n"
     ]
    }
   ],
   "source": [
    "raw_df['contractions_num'] = [get_contractions(text) for text in raw_df.Text]\n",
    "raw_df['emotionalpunctuations_num'] = [get_punctuation_number(text) for text in raw_df.Text]\n",
    "raw_df['readable_num'] = [get_readable_words(text) for text in raw_df.Text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.to_csv(r'C:\\Users\\School\\Desktop\\4222\\Project MBTI\\All Features on Raw Data Part 1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_excel('BT4222_Combined_dataset_Version 2.xlsx')\n",
    "raw_df\n",
    "# basic cleaning \n",
    "raw_df['Text'] = [str(text).replace(':', '',) for text in raw_df.Text]\n",
    "raw_df['Text'] = [str(text).replace('/', '',) for text in raw_df.Text]\n",
    "raw_df = raw_df[raw_df['Text']!= \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Text</th>\n",
       "      <th>Reddit</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Typology</th>\n",
       "      <th>Kaggle</th>\n",
       "      <th>hedge_perc</th>\n",
       "      <th>firstperson_perc</th>\n",
       "      <th>thirdperson_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Meme&lt;3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>MemeIncorrect Quote? Not so sure. Just me, try...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>MemeENFP Avatar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>MemeFour Distinct Flavors of NT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>StereotypesINFP </td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214114</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>httpswww.youtube.comwatch?v=t8edHB_h908|||IxFP...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.439483</td>\n",
       "      <td>0.056404</td>\n",
       "      <td>0.056404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214115</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.510504</td>\n",
       "      <td>0.111345</td>\n",
       "      <td>0.055322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214116</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.397990</td>\n",
       "      <td>0.050251</td>\n",
       "      <td>0.060302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214117</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.464088</td>\n",
       "      <td>0.109392</td>\n",
       "      <td>0.045856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214118</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490405</td>\n",
       "      <td>0.122246</td>\n",
       "      <td>0.059701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212138 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag                                               Text  Reddit  \\\n",
       "0       INFP                                            Meme<3        1   \n",
       "1       ENFJ  MemeIncorrect Quote? Not so sure. Just me, try...       1   \n",
       "2       INTP                                   MemeENFP Avatar        1   \n",
       "3       ENTP                   MemeFour Distinct Flavors of NT        1   \n",
       "4       INTJ                                 StereotypesINFP         1   \n",
       "...      ...                                                ...     ...   \n",
       "214114  ISFP  httpswww.youtube.comwatch?v=t8edHB_h908|||IxFP...       0   \n",
       "214115  ENFP  'So...if this thread already exists someplace ...       0   \n",
       "214116  INTP  'So many questions when i do these things.  I ...       0   \n",
       "214117  INFP  'I am very conflicted right now when it comes ...       0   \n",
       "214118  INFP  'It has been too long since I have been on per...       0   \n",
       "\n",
       "        Twitter  Typology  Kaggle  hedge_perc  firstperson_perc  \\\n",
       "0             0         0       0    0.000000          0.000000   \n",
       "1             0         0       0    1.000000          0.187500   \n",
       "2             0         0       0    0.000000          0.000000   \n",
       "3             0         0       0    0.400000          0.000000   \n",
       "4             0         0       0    0.000000          0.000000   \n",
       "...         ...       ...     ...         ...               ...   \n",
       "214114        0         0       1    0.439483          0.056404   \n",
       "214115        0         0       1    0.510504          0.111345   \n",
       "214116        0         0       1    0.397990          0.050251   \n",
       "214117        0         0       1    0.464088          0.109392   \n",
       "214118        0         0       1    0.490405          0.122246   \n",
       "\n",
       "        thirdperson_perc  \n",
       "0               0.000000  \n",
       "1               0.000000  \n",
       "2               0.000000  \n",
       "3               0.000000  \n",
       "4               0.000000  \n",
       "...                  ...  \n",
       "214114          0.056404  \n",
       "214115          0.055322  \n",
       "214116          0.060302  \n",
       "214117          0.045856  \n",
       "214118          0.059701  \n",
       "\n",
       "[212138 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['hedge_perc'] = [get_hedge(text) for text in raw_df.Text]\n",
    "raw_df['firstperson_perc'] = [get_firstperson(text) for text in raw_df.Text]\n",
    "raw_df['thirdperson_perc'] = [get_thirdperson(text) for text in raw_df.Text]\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.to_csv(r'C:\\Users\\School\\Desktop\\4222\\Project MBTI\\All Features on Raw Data Part 2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_excel('BT4222_Combined_dataset_Version 2.xlsx')\n",
    "raw_df\n",
    "# basic cleaning \n",
    "raw_df['Text'] = [str(text).replace(':', '',) for text in raw_df.Text]\n",
    "raw_df['Text'] = [str(text).replace('/', '',) for text in raw_df.Text]\n",
    "raw_df = raw_df[raw_df['Text']!= \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_readability(text):\n",
    "    results = readability.getmeasures(text, lang='en')\n",
    "    #print(results['readability grades']['FleschReadingEase'])\n",
    "    return results\n",
    "\n",
    "#get_readability(\"Because of you.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Text</th>\n",
       "      <th>Reddit</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Typology</th>\n",
       "      <th>Kaggle</th>\n",
       "      <th>Kincaid</th>\n",
       "      <th>ARI</th>\n",
       "      <th>Coleman-Liau</th>\n",
       "      <th>FleschReadingEase</th>\n",
       "      <th>...</th>\n",
       "      <th>conjunction</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>preposition</th>\n",
       "      <th>nominalization</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>interrogative</th>\n",
       "      <th>article</th>\n",
       "      <th>subordination</th>\n",
       "      <th>conjunction</th>\n",
       "      <th>preposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Meme&lt;3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.91</td>\n",
       "      <td>-8.655</td>\n",
       "      <td>-15.894816</td>\n",
       "      <td>162.505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>MemeIncorrect Quote? Not so sure. Just me, try...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.42</td>\n",
       "      <td>5.852</td>\n",
       "      <td>6.922085</td>\n",
       "      <td>90.090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>MemeENFP Avatar</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.79</td>\n",
       "      <td>12.540</td>\n",
       "      <td>10.564513</td>\n",
       "      <td>35.605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>MemeFour Distinct Flavors of NT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.24</td>\n",
       "      <td>6.504</td>\n",
       "      <td>10.032935</td>\n",
       "      <td>66.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>StereotypesINFP </td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>49.720</td>\n",
       "      <td>42.809681</td>\n",
       "      <td>-132.580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214114</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>httpswww.youtube.comwatch?v=t8edHB_h908|||IxFP...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214115</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214116</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214117</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214118</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214119 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag                                               Text  Reddit  \\\n",
       "0       INFP                                            Meme<3      1.0   \n",
       "1       ENFJ  MemeIncorrect Quote? Not so sure. Just me, try...     1.0   \n",
       "2       INTP                                   MemeENFP Avatar      1.0   \n",
       "3       ENTP                   MemeFour Distinct Flavors of NT      1.0   \n",
       "4       INTJ                                 StereotypesINFP       1.0   \n",
       "...      ...                                                ...     ...   \n",
       "214114  ISFP  httpswww.youtube.comwatch?v=t8edHB_h908|||IxFP...     0.0   \n",
       "214115  ENFP  'So...if this thread already exists someplace ...     0.0   \n",
       "214116  INTP  'So many questions when i do these things.  I ...     0.0   \n",
       "214117  INFP  'I am very conflicted right now when it comes ...     0.0   \n",
       "214118  INFP  'It has been too long since I have been on per...     0.0   \n",
       "\n",
       "        Twitter  Typology  Kaggle  Kincaid     ARI  Coleman-Liau  \\\n",
       "0           0.0       0.0     0.0    -8.91  -8.655    -15.894816   \n",
       "1           0.0       0.0     0.0     4.42   5.852      6.922085   \n",
       "2           0.0       0.0     0.0     8.79  12.540     10.564513   \n",
       "3           0.0       0.0     0.0     5.24   6.504     10.032935   \n",
       "4           0.0       0.0     0.0    32.00  49.720     42.809681   \n",
       "...         ...       ...     ...      ...     ...           ...   \n",
       "214114      0.0       0.0     1.0      NaN     NaN           NaN   \n",
       "214115      0.0       0.0     1.0      NaN     NaN           NaN   \n",
       "214116      0.0       0.0     1.0      NaN     NaN           NaN   \n",
       "214117      0.0       0.0     1.0      NaN     NaN           NaN   \n",
       "214118      0.0       0.0     1.0      NaN     NaN           NaN   \n",
       "\n",
       "        FleschReadingEase  ...  conjunction  pronoun  preposition  \\\n",
       "0                 162.505  ...          0.0      0.0          0.0   \n",
       "1                  90.090  ...          0.0      2.0          2.0   \n",
       "2                  35.605  ...          0.0      0.0          0.0   \n",
       "3                  66.400  ...          0.0      0.0          1.0   \n",
       "4                -132.580  ...          0.0      0.0          0.0   \n",
       "...                   ...  ...          ...      ...          ...   \n",
       "214114                NaN  ...          NaN      NaN          NaN   \n",
       "214115                NaN  ...          NaN      NaN          NaN   \n",
       "214116                NaN  ...          NaN      NaN          NaN   \n",
       "214117                NaN  ...          NaN      NaN          NaN   \n",
       "214118                NaN  ...          NaN      NaN          NaN   \n",
       "\n",
       "        nominalization  pronoun  interrogative  article  subordination  \\\n",
       "0                  0.0      0.0            0.0      0.0            0.0   \n",
       "1                  0.0      0.0            0.0      0.0            0.0   \n",
       "2                  0.0      0.0            0.0      0.0            0.0   \n",
       "3                  0.0      0.0            0.0      0.0            0.0   \n",
       "4                  0.0      0.0            0.0      0.0            0.0   \n",
       "...                ...      ...            ...      ...            ...   \n",
       "214114             NaN      NaN            NaN      NaN            NaN   \n",
       "214115             NaN      NaN            NaN      NaN            NaN   \n",
       "214116             NaN      NaN            NaN      NaN            NaN   \n",
       "214117             NaN      NaN            NaN      NaN            NaN   \n",
       "214118             NaN      NaN            NaN      NaN            NaN   \n",
       "\n",
       "        conjunction  preposition  \n",
       "0               0.0          0.0  \n",
       "1               0.0          0.0  \n",
       "2               0.0          0.0  \n",
       "3               0.0          0.0  \n",
       "4               0.0          0.0  \n",
       "...             ...          ...  \n",
       "214114          NaN          NaN  \n",
       "214115          NaN          NaN  \n",
       "214116          NaN          NaN  \n",
       "214117          NaN          NaN  \n",
       "214118          NaN          NaN  \n",
       "\n",
       "[214119 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dict = get_readability(\"Why are you calling me?\" )\n",
    "\n",
    "measures_name = []\n",
    "for department in read_dict:\n",
    "    for measures in read_dict[department]:\n",
    "        measures_name.append(measures)\n",
    "        \n",
    "readability_df = pd.DataFrame(columns = measures_name)\n",
    "\n",
    "for index, row in raw_df.iterrows():\n",
    "    measures_list = []\n",
    "    text = row.Text\n",
    "    try:\n",
    "        read_dict = get_readability(text)\n",
    "        for department in read_dict:\n",
    "            for measures in read_dict[department]:\n",
    "                measures_list.append(read_dict[department][measures])\n",
    "    except:\n",
    "        read_dict = get_readability('null')\n",
    "        for department in read_dict:\n",
    "            for measures in read_dict[department]:\n",
    "                measures_list.append(None)\n",
    "\n",
    "    readability_df.loc[len(readability_df)] = measures_list\n",
    "\n",
    "final_df = pd.concat([raw_df,readability_df], axis=1)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(r'C:\\Users\\School\\Desktop\\4222\\Project MBTI\\All Features on Raw Data Part 3.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
