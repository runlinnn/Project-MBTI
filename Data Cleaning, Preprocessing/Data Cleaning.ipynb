{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import texthero as hero\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gingerit.gingerit import GingerIt\n",
    "\n",
    "import emoji\n",
    "import regex\n",
    "\n",
    "import multiprocessing\n",
    "import docx2txt\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data and basic Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"BT4222_Combined_dataset_Version 2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"All Features on Raw Data Part 1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.drop(columns=[\"Reddit\",\"Twitter\",\"Typology\",\"Kaggle\",\"Afinn Score\",\"Polarity\",\"Subjectivity\",\"Length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Text</th>\n",
       "      <th>num_noun</th>\n",
       "      <th>num_adj</th>\n",
       "      <th>num_prep</th>\n",
       "      <th>num_det</th>\n",
       "      <th>num_pron</th>\n",
       "      <th>num_verb</th>\n",
       "      <th>num_adverb</th>\n",
       "      <th>num_interject</th>\n",
       "      <th>...</th>\n",
       "      <th>conjunction</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>preposition</th>\n",
       "      <th>nominalization</th>\n",
       "      <th>pronoun.1</th>\n",
       "      <th>interrogative</th>\n",
       "      <th>article</th>\n",
       "      <th>subordination</th>\n",
       "      <th>conjunction.1</th>\n",
       "      <th>preposition.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Meme&lt;3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>MemeIncorrect Quote? Not so sure. Just me, try...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>MemeENFP Avatar</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>MemeFour Distinct Flavors of NT</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>StereotypesINFP ðŸ¦‹</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212133</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>httpswww.youtube.comwatch?v=t8edHB_h908|||IxFP...</td>\n",
       "      <td>191</td>\n",
       "      <td>74</td>\n",
       "      <td>93</td>\n",
       "      <td>69</td>\n",
       "      <td>95</td>\n",
       "      <td>185</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212134</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>314</td>\n",
       "      <td>91</td>\n",
       "      <td>116</td>\n",
       "      <td>91</td>\n",
       "      <td>201</td>\n",
       "      <td>329</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212135</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>256</td>\n",
       "      <td>69</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>125</td>\n",
       "      <td>210</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212136</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>323</td>\n",
       "      <td>113</td>\n",
       "      <td>218</td>\n",
       "      <td>137</td>\n",
       "      <td>253</td>\n",
       "      <td>398</td>\n",
       "      <td>183</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212137</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>249</td>\n",
       "      <td>92</td>\n",
       "      <td>116</td>\n",
       "      <td>97</td>\n",
       "      <td>210</td>\n",
       "      <td>325</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212138 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag                                               Text  num_noun  \\\n",
       "0       INFP                                            Meme<3          1   \n",
       "1       ENFJ  MemeIncorrect Quote? Not so sure. Just me, try...         6   \n",
       "2       INTP                                   MemeENFP Avatar          2   \n",
       "3       ENTP                   MemeFour Distinct Flavors of NT          4   \n",
       "4       INTJ                                 StereotypesINFP ðŸ¦‹          2   \n",
       "...      ...                                                ...       ...   \n",
       "212133  ISFP  httpswww.youtube.comwatch?v=t8edHB_h908|||IxFP...       191   \n",
       "212134  ENFP  'So...if this thread already exists someplace ...       314   \n",
       "212135  INTP  'So many questions when i do these things.  I ...       256   \n",
       "212136  INFP  'I am very conflicted right now when it comes ...       323   \n",
       "212137  INFP  'It has been too long since I have been on per...       249   \n",
       "\n",
       "        num_adj  num_prep  num_det  num_pron  num_verb  num_adverb  \\\n",
       "0             0         0        0         0         1           0   \n",
       "1             1         1        1         2         2           2   \n",
       "2             0         0        0         0         0           0   \n",
       "3             0         1        0         0         0           0   \n",
       "4             0         0        0         0         0           0   \n",
       "...         ...       ...      ...       ...       ...         ...   \n",
       "212133       74        93       69        95       185          64   \n",
       "212134       91       116       91       201       329         112   \n",
       "212135       69        88       80       125       210          61   \n",
       "212136      113       218      137       253       398         183   \n",
       "212137       92       116       97       210       325         140   \n",
       "\n",
       "        num_interject  ...  conjunction  pronoun  preposition  nominalization  \\\n",
       "0                   0  ...          0.0      0.0          0.0             0.0   \n",
       "1                   0  ...          0.0      2.0          2.0             0.0   \n",
       "2                   0  ...          0.0      0.0          0.0             0.0   \n",
       "3                   0  ...          0.0      0.0          1.0             0.0   \n",
       "4                   0  ...          0.0      0.0          0.0             0.0   \n",
       "...               ...  ...          ...      ...          ...             ...   \n",
       "212133              1  ...         26.0    129.0         93.0             7.0   \n",
       "212134              0  ...         75.0    251.0        140.0             8.0   \n",
       "212135              1  ...         32.0    155.0         96.0             9.0   \n",
       "212136              3  ...         63.0    300.0        216.0            13.0   \n",
       "212137              0  ...         60.0    259.0        153.0             9.0   \n",
       "\n",
       "        pronoun.1  interrogative  article  subordination  conjunction.1  \\\n",
       "0             0.0            0.0      0.0            0.0            0.0   \n",
       "1             0.0            0.0      0.0            0.0            0.0   \n",
       "2             0.0            0.0      0.0            0.0            0.0   \n",
       "3             0.0            0.0      0.0            0.0            0.0   \n",
       "4             0.0            0.0      0.0            0.0            0.0   \n",
       "...           ...            ...      ...            ...            ...   \n",
       "212133        0.0            0.0      0.0            0.0            0.0   \n",
       "212134        0.0            0.0      0.0            0.0            0.0   \n",
       "212135        0.0            0.0      0.0            0.0            0.0   \n",
       "212136        0.0            0.0      0.0            0.0            0.0   \n",
       "212137        0.0            0.0      0.0            0.0            0.0   \n",
       "\n",
       "        preposition.1  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "212133            0.0  \n",
       "212134            0.0  \n",
       "212135            0.0  \n",
       "212136            0.0  \n",
       "212137            0.0  \n",
       "\n",
       "[212138 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Text</th>\n",
       "      <th>Reddit</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Typology</th>\n",
       "      <th>Kaggle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Meme&lt;3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>MemeIncorrect Quote? Not so sure. Just me, try...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>MemeENFP Avatar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>MemeFour Distinct Flavors of NT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>StereotypesINFP ðŸ¦‹</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214114</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>https://www.youtube.com/watch?v=t8edHB_h908|||...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214115</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214116</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214117</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214118</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214119 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag                                               Text  Reddit  \\\n",
       "0       INFP                                            Meme<3        1   \n",
       "1       ENFJ  MemeIncorrect Quote? Not so sure. Just me, try...       1   \n",
       "2       INTP                                   MemeENFP Avatar        1   \n",
       "3       ENTP                   MemeFour Distinct Flavors of NT        1   \n",
       "4       INTJ                                 StereotypesINFP ðŸ¦‹        1   \n",
       "...      ...                                                ...     ...   \n",
       "214114  ISFP  https://www.youtube.com/watch?v=t8edHB_h908|||...       0   \n",
       "214115  ENFP  'So...if this thread already exists someplace ...       0   \n",
       "214116  INTP  'So many questions when i do these things.  I ...       0   \n",
       "214117  INFP  'I am very conflicted right now when it comes ...       0   \n",
       "214118  INFP  'It has been too long since I have been on per...       0   \n",
       "\n",
       "        Twitter  Typology  Kaggle  \n",
       "0             0         0       0  \n",
       "1             0         0       0  \n",
       "2             0         0       0  \n",
       "3             0         0       0  \n",
       "4             0         0       0  \n",
       "...         ...       ...     ...  \n",
       "214114        0         0       1  \n",
       "214115        0         0       1  \n",
       "214116        0         0       1  \n",
       "214117        0         0       1  \n",
       "214118        0         0       1  \n",
       "\n",
       "[214119 rows x 6 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mbti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti['Tag'] = df_mbti['Tag'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"MBTI\", \"ISTJ\", \"ISTP\", \"ISFJ\", \"ISFP\", \"INFJ\", \"INFP\", \"INTJ\", \"INTP\", \"ESTP\", \"ESTJ\",\"ESFP\", \"ESFJ\", \"ENFP\", \"ENFJ\", \"ENTP\", \"ENTJ\"]\n",
    "df_mbti = df_mbti[df_mbti.Tag.isin(titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti = df_mbti.dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons_.extend(list(emoji.UNICODE_EMOJI['en'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoticons_count(line):\n",
    "    count = sum(item in i for i in line.split() for item in emoticons_)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti['Text'] = df_mbti['Text'].apply(lambda x: \" \".join(x for x in str(x).split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti['Emoticons count'] = df_mbti['Text'].apply(lambda x: emoticons_count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Text</th>\n",
       "      <th>Reddit</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Typology</th>\n",
       "      <th>Kaggle</th>\n",
       "      <th>Emoticons count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Meme&lt;3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>MemeIncorrect Quote? Not so sure. Just me, try...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>MemeENFP Avatar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>MemeFour Distinct Flavors of NT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>StereotypesINFP ðŸ¦‹</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214114</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>https://www.youtube.com/watch?v=t8edHB_h908|||...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214115</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214116</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things. I w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214117</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214118</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150794 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag                                               Text  Reddit  \\\n",
       "0       INFP                                             Meme<3       1   \n",
       "1       ENFJ  MemeIncorrect Quote? Not so sure. Just me, try...       1   \n",
       "2       INTP                                    MemeENFP Avatar       1   \n",
       "3       ENTP                    MemeFour Distinct Flavors of NT       1   \n",
       "4       INTJ                                  StereotypesINFP ðŸ¦‹       1   \n",
       "...      ...                                                ...     ...   \n",
       "214114  ISFP  https://www.youtube.com/watch?v=t8edHB_h908|||...       0   \n",
       "214115  ENFP  'So...if this thread already exists someplace ...       0   \n",
       "214116  INTP  'So many questions when i do these things. I w...       0   \n",
       "214117  INFP  'I am very conflicted right now when it comes ...       0   \n",
       "214118  INFP  'It has been too long since I have been on per...       0   \n",
       "\n",
       "        Twitter  Typology  Kaggle  Emoticons count  \n",
       "0             0         0       0                1  \n",
       "1             0         0       0                1  \n",
       "2             0         0       0                0  \n",
       "3             0         0       0                0  \n",
       "4             0         0       0                1  \n",
       "...         ...       ...     ...              ...  \n",
       "214114        0         0       1               13  \n",
       "214115        0         0       1               22  \n",
       "214116        0         0       1                2  \n",
       "214117        0         0       1                1  \n",
       "214118        0         0       1               13  \n",
       "\n",
       "[150794 rows x 7 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mbti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keeping only English words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti['Text'] =df_mbti['Text'].astype(str).apply(lambda x: ''.join([i if ord(i) < 128 else ' ' for i in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['Text'] =raw_data['Text'].astype(str).apply(lambda x: ''.join([i if ord(i) < 128 else ' ' for i in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Text</th>\n",
       "      <th>Reddit</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Typology</th>\n",
       "      <th>Kaggle</th>\n",
       "      <th>Emoticons count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Meme&lt;3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>MemeIncorrect Quote? Not so sure. Just me, try...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>MemeENFP Avatar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>MemeFour Distinct Flavors of NT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>StereotypesINFP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214114</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>https://www.youtube.com/watch?v=t8edHB_h908|||...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214115</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214116</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things. I w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214117</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214118</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150794 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag                                               Text  Reddit  \\\n",
       "0       INFP                                             Meme<3       1   \n",
       "1       ENFJ  MemeIncorrect Quote? Not so sure. Just me, try...       1   \n",
       "2       INTP                                    MemeENFP Avatar       1   \n",
       "3       ENTP                    MemeFour Distinct Flavors of NT       1   \n",
       "4       INTJ                                  StereotypesINFP         1   \n",
       "...      ...                                                ...     ...   \n",
       "214114  ISFP  https://www.youtube.com/watch?v=t8edHB_h908|||...       0   \n",
       "214115  ENFP  'So...if this thread already exists someplace ...       0   \n",
       "214116  INTP  'So many questions when i do these things. I w...       0   \n",
       "214117  INFP  'I am very conflicted right now when it comes ...       0   \n",
       "214118  INFP  'It has been too long since I have been on per...       0   \n",
       "\n",
       "        Twitter  Typology  Kaggle  Emoticons count  \n",
       "0             0         0       0                1  \n",
       "1             0         0       0                1  \n",
       "2             0         0       0                0  \n",
       "3             0         0       0                0  \n",
       "4             0         0       0                1  \n",
       "...         ...       ...     ...              ...  \n",
       "214114        0         0       1               13  \n",
       "214115        0         0       1               22  \n",
       "214116        0         0       1                2  \n",
       "214117        0         0       1                1  \n",
       "214118        0         0       1               13  \n",
       "\n",
       "[150794 rows x 7 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mbti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expanding contractions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "# Function for expanding contractions\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti['Text'] =df_mbti['Text'].astype(str).apply(lambda x: expand_contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['Text'] =raw_data['Text'].astype(str).apply(lambda x: expand_contractions(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning with texthero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_pipeline = [hero.preprocessing.fillna,\n",
    "                   hero.preprocessing.lowercase,\n",
    "                   hero.preprocessing.remove_whitespace,\n",
    "                   hero.preprocessing.remove_urls,\n",
    "                   hero.preprocessing.remove_diacritics,\n",
    "                   hero.preprocessing.remove_urls,\n",
    "                   hero.preprocessing.remove_html_tags\n",
    "                   ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti['Text'] = df_mbti['Text'].pipe(hero.clean, custom_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['Text'] = raw_data['Text'].pipe(hero.clean, custom_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Text</th>\n",
       "      <th>Reddit</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Typology</th>\n",
       "      <th>Kaggle</th>\n",
       "      <th>Emoticons count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>meme&lt;3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>memeincorrect quote? not so sure. just me, try...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>memeenfp avatar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>memefour distinct flavors of nt</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>stereotypesinfp</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214114</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>just because i always think of cats as fi do...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214115</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'so...if this thread already exists someplace ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214116</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'so many questions when i do these things. i w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214117</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'i am very conflicted right now when it comes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214118</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'it has been too long since i have been on per...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150794 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag                                               Text  Reddit  \\\n",
       "0       INFP                                             meme<3       1   \n",
       "1       ENFJ  memeincorrect quote? not so sure. just me, try...       1   \n",
       "2       INTP                                    memeenfp avatar       1   \n",
       "3       ENTP                    memefour distinct flavors of nt       1   \n",
       "4       INTJ                                    stereotypesinfp       1   \n",
       "...      ...                                                ...     ...   \n",
       "214114  ISFP    just because i always think of cats as fi do...       0   \n",
       "214115  ENFP  'so...if this thread already exists someplace ...       0   \n",
       "214116  INTP  'so many questions when i do these things. i w...       0   \n",
       "214117  INFP  'i am very conflicted right now when it comes ...       0   \n",
       "214118  INFP  'it has been too long since i have been on per...       0   \n",
       "\n",
       "        Twitter  Typology  Kaggle  Emoticons count  \n",
       "0             0         0       0                1  \n",
       "1             0         0       0                1  \n",
       "2             0         0       0                0  \n",
       "3             0         0       0                0  \n",
       "4             0         0       0                1  \n",
       "...         ...       ...     ...              ...  \n",
       "214114        0         0       1               13  \n",
       "214115        0         0       1               22  \n",
       "214116        0         0       1                2  \n",
       "214117        0         0       1                1  \n",
       "214118        0         0       1               13  \n",
       "\n",
       "[150794 rows x 7 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mbti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retaining Emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons = {\n",
    "    \":)\": \"absmile\",\n",
    "    \"<3\": \"bcheart\",\n",
    "    \"(:\": \"cdsmile\",\n",
    "    \"(-:\": \"desmile\",\n",
    "    \":-)\": \"efsmile\",\n",
    "    \"(=\": \"fgsmile\",\n",
    "    \"=)\": \"ghsmile\",\n",
    "    \":p\": \"hjwink\",\n",
    "    \":P\": \"ijwink\",\n",
    "    \":D\": \"jksmile\",\n",
    "    \"xD\": \"klsmile\",\n",
    "    \"XD\": \"lmsmile\",\n",
    "    \":/\": \"mndisap\",\n",
    "    \"/:\": \"nodisap\",\n",
    "    \":|\": \"opdisap\",\n",
    "    \":]\": \"pqsmile\",\n",
    "    \"8)\": \"qrsmile\",\n",
    "    \"=D\": \"rssmile\",\n",
    "    \"8D\": \"stsmile\",\n",
    "    \";D\": \"tuwink\",\n",
    "    \";)\": \"uvwink\",\n",
    "    \"):\": \"vwsad\",\n",
    "    \");\": \"wxsad\",\n",
    "    \":-(\": \"xysad\",\n",
    "    \":[\": \"yzsad\",\n",
    "    \":')\": \"zalaugh\",\n",
    "    \":'(\": \"abecry\",\n",
    "    \":x\": \"cbdkiss\",\n",
    "    \":o\": \"dfgsurprise\",\n",
    "    \":0\": \"xyshock\",\n",
    "    \":O\": \"xysurprise\",\n",
    "    \"D;\": \"xydisgust\",\n",
    "    \"DX\": \"xyhorror\",\n",
    "    \"D8\": \"abhorror\"\n",
    "\n",
    "}\n",
    "\n",
    "emoticons_inverse = {v: k for k, v in emoticons.items()}\n",
    "\n",
    "punctuation = \",./<>?;':\\\"[]\\\\{}|`~!@#$%^&*()_+-=\"\n",
    "\n",
    "emoticons_ = list(emoticons.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_clean = []\n",
    "\n",
    "for line in raw_data['Text']:\n",
    "    #Replace emoticons with non-punctuation\n",
    "    for emote, rpl in emoticons.items():\n",
    "        line = line.replace(emote, \" \"+rpl+\" \")\n",
    "        \n",
    "    line = line.replace('\\d+', '')\n",
    "    #Remove punctuation\n",
    "    for char in line:\n",
    "        if char in punctuation:\n",
    "            line = line.replace(char, \"\")\n",
    "\n",
    "    #Revert emoticons\n",
    "    for emote, rpl in emoticons_inverse.items():\n",
    "        line = line.replace(emote, rpl)\n",
    "\n",
    "    lines_clean.append(line)\n",
    "\n",
    "raw_data['Text'] = lines_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_clean = []\n",
    "\n",
    "for line in df_mbti['Text']:\n",
    "    #Replace emoticons with non-punctuation\n",
    "    for emote, rpl in emoticons.items():\n",
    "        line = line.replace(emote, \" \"+rpl+\" \")\n",
    "        \n",
    "    line = line.replace('\\d+', '')\n",
    "    #Remove punctuation\n",
    "    for char in line:\n",
    "        if char in punctuation:\n",
    "            line = line.replace(char, \"\")\n",
    "\n",
    "    #Revert emoticons\n",
    "    for emote, rpl in emoticons_inverse.items():\n",
    "        line = line.replace(emote, rpl)\n",
    "\n",
    "    lines_clean.append(line)\n",
    "\n",
    "df_mbti['Text'] = lines_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti['Text'] = hero.remove_whitespace(df_mbti['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "\n",
    "\n",
    "#df_mbti['Text'] =df_mbti['Text'].astype(str).apply(clean_text)\n",
    "raw_data['Text'] =raw_data['Text'].astype(str).apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping empty rows and duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti = df_mbti.dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spelling Harmonisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all(text, mydict):\n",
    "    for gb, us in mydict.items():\n",
    "        text = text.replace(us, gb)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#harmonising spelling\n",
    "df_mbti['Text'] = df_mbti['Text'].apply(lambda x: replace_all(x, us2gb))\n",
    "\n",
    "# Run the cell with us2gb all the way at the bottom of the notebook!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['Text'] = raw_data['Text'].apply(lambda x: replace_all(x, us2gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming and processing using Gensim's library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    return stemmer.stem(text)\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti['Text_stemmed'] = df_mbti['Text'].map(preprocess)\n",
    "df_mbti['Text_stemmed'] = [','.join(map(str, l)).replace(\",\", \" \") for l in df_mbti['Text_stemmed']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing lines with less than 10 characters or less than or equal to 2 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti = df_mbti[~df_mbti['Text'].str.split().str.len().lt(3)]\n",
    "# df_mbti = df_mbti[df_mbti['Cleaned_text'].apply(len)>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data[~raw_data['Text'].str.split().str.len().lt(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can use this for obtaining Noun Chunks but it takes too Long to run. I have used Bigrams instead. Similar purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nc_gen(line):\n",
    "\n",
    "    chunk = []\n",
    "    for word in nlp(line).noun_chunks:\n",
    "            chunk.append(word)\n",
    "    return chunk\n",
    "        \n",
    "        \n",
    "# df_mbti['Noun_chunks'] = df_mbti['Cleaned_Text'].apply(lambda x: nc_gen(x)) \n",
    "# too slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorising. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can play around with the type and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vect = TfidfVectorizer()\n",
    "vect = CountVectorizer(max_df=0.7, max_features=5000)\n",
    "#can change the max_features, max_df\n",
    "dtm = pd.DataFrame(vect.fit_transform(df_mbti['Text']).toarray(), columns=vect.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00100000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>youri</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youve</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127578</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127579</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127580</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127581</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127582</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127583 rows Ã— 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00100000  10  100  1000  11  12  13  14  15  16  ...  youre  youri  \\\n",
       "0              0   0    0     0   0   0   0   0   0   0  ...      0      0   \n",
       "1              0   0    0     0   0   0   0   0   0   0  ...      0      0   \n",
       "2              0   0    0     0   0   0   0   0   0   0  ...      0      0   \n",
       "3              0   0    0     0   0   0   0   0   0   0  ...      0      0   \n",
       "4              0   0    0     0   0   0   0   0   0   0  ...      0      0   \n",
       "...          ...  ..  ...   ...  ..  ..  ..  ..  ..  ..  ...    ...    ...   \n",
       "127578         0   0    0     0   0   0   0   0   0   0  ...      1      0   \n",
       "127579         0   0    0     0   0   0   0   0   0   0  ...      5      0   \n",
       "127580         0   0    1     1   0   0   0   0   0   0  ...      0      0   \n",
       "127581         0   1    0     0   0   0   0   0   0   0  ...      0      0   \n",
       "127582         0   0    0     0   0   0   0   0   0   0  ...      0      0   \n",
       "\n",
       "        youth  youtube  youve  yup  zero  zodiac  zombie  zone  \n",
       "0           0        0      0    0     0       0       0     0  \n",
       "1           0        0      0    0     0       0       0     0  \n",
       "2           0        0      0    0     0       0       0     0  \n",
       "3           0        0      0    0     0       0       0     0  \n",
       "4           0        0      0    0     0       0       0     0  \n",
       "...       ...      ...    ...  ...   ...     ...     ...   ...  \n",
       "127578      0        1      0    0     0       0       0     0  \n",
       "127579      0        0      0    0     0       0       0     0  \n",
       "127580      0        0      0    0     0       0       0     0  \n",
       "127581      0        0      0    0     0       0       0     0  \n",
       "127582      0        0      0    0     0       0       0     0  \n",
       "\n",
       "[127583 rows x 5000 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti = df_mbti.reset_index().drop(columns = [\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.reset_index().drop(columns = [\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wrap', 'wrapped', 'write', 'writer', 'writers', 'writing', 'written', 'wrong', 'wrote', 'wtf', 'xd', 'xdi', 'xnfp', 'xntp', 'xstj', 'ya', 'yall', 'yang', 'yay', 'yea', 'yeah', 'year', 'years', 'yell', 'yelling', 'yellow', 'yep', 'yes', 'yesterday', 'yet', 'yeu', 'yo', 'yoga', 'york', 'youd', 'youi', 'youll', 'young', 'younger', 'youngest', 'youre', 'youri', 'youth', 'youtube', 'youve', 'yup', 'zero', 'zodiac', 'zombie', 'zone']\n"
     ]
    }
   ],
   "source": [
    "print(vect.get_feature_names()[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127577"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_mbti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'understand x existshappens think going make story make sure tell children think religioni actually find estps one easiest types identify theyre much better repeating working process long keep profiting one odd jobsthis thing youth think still hit wall time time learned push magic pull sudden makes sudden immune toare currently committed allowing one person plow foreseeable futuregetting ball rolling projects probably opportunistic nts xntjs plan plan something satisfied fail intps actually likewell difference estp entp salesman estp memorize technical jargon repeat client whereas entp actually understand technicali business last three years decided close primarily due retarded supplier hurt business point could recover none ihello percy friends absent forums months mainly lost interest mbti little although automatically trying type everyone meet nicethe best way describe beliefs agnostic atheist cannot definitively prove god exist cannot definitively prove teacup orbiting around jupiter buti think lawrence krauss entpintjs awesome cause focused theyre imagine could get hump actually apply 100usually time wake bladder collected lot urine since time fell asleep general discomfort full bladder knowledge urinate thati assume idiot provide evidence proving otherwisei text logistical purposes cannot talk right moment feel like actually talking said person reason still find hilariousam one reading title thread needing company thought misplaced craigslist personals adactually last post quite blunt enough thread actually caring understanding situation giving advice part someone tells problem xbasically told people past absorbant emotional tampon words understand someone might going emotional hardshipthe time jump nowone year later scored 15 19 maybe cause really began embracing inner machiavallian last little today one housemates crying ithe result still though whether someone killed purpose accident matter sense regardless intent said person still dead cannot brought backi put lot faith words way get people want thoughts important words ultimately one actions define yourso anyone live colorado washington dthe microwave oven making men feel competent kitchen since 1967this song made gingertonic flattered think know actions need take order fulfill vision going bother talking strategy comes youi would label kind personality disorder certain characteristics noticed becoming narcissistic learning hide better learned thati got 18 lower expected scored high narcissistic traits charm lying manipulative grandiosity known narcissist extreme onefeel nothing brotheri think would suck blind visual learnerthanks plan hobby keep sane vision make music women listen clothes automatically fly think possiblemeh people deserve time casual acquaintances easily accessible give damn people constantly calling hang usuallyi relationship expert means people removed life bring annoyance positivity average 5 people spend mostforget mbti second take calculated risks thing perfect idea otherwise someone else done already everyone gets ideas people act oni kind weird new people met know well extremely smooth charming get know people better turn get know smoothnessi really hope never daughternfs often grosslyenlarged moral compass limit much action take would waste time truthfully although media tells people dothanks man secretive goal create music makes chicks take shirts simply listening think possiblei may misrepresented see successful least yet lofty goals people tend think crazy going anyways peoplei think n trait nts overanalyze logical problems nfs overanalyze emotional shitto mildmannered andor unsuccessful folk come across arrogant ass lot time really think world especially starting seeall entp threads brag threads albino mallato guessing midtolate teens issue back age idea wanted icongrats great use newfound type discover certain skills may known otherwise try change fit type accurately youd bewe make easy people chirp us feel guilty quite frankly kind deserve ityep parents consider selfish wrong see point going help someone something easily themselvesit made laughi think everyday goal interest becoming political leader ones change world anyways ceos ceos politicians inanother one johnny ableton kirstein song feat johnny sr free download john kirstein soundcloud create record share sounds freeright cut right calf idea came theres also bruise forehead im confused cause remember hitting head anythingmy main goal seen competent fun truthfully would rather called intimidating adorablegood analysis calm philosophic view entrepreneurship seen natural entrepreneur since officially started 25 years ago always something side'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mbti.iloc[120000]['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(message_id):\n",
    "\n",
    "    message_text = df_mbti.loc[message_id, 'Text']\n",
    "    print(message_text)\n",
    "    print(df_mbti.loc[message_id, 'Tag'])\n",
    "\n",
    "    \n",
    "    # create a list of all unique words in the review (minus stop words) using CountVectorizer\n",
    "    unique_words = vect.get_feature_names()\n",
    "    \n",
    "    # create a dictionary of words and their TF-IDF scores\n",
    "    word_scores = {}\n",
    "    for word in unique_words:\n",
    "        word_scores[word] = dtm.iloc[message_id, unique_words.index(word)]\n",
    "        \n",
    "    \n",
    "    # print words with the top 5 TF-IDF scores\n",
    "    print('\\n'+'TOP SCORING WORDS:')\n",
    "    top_scores = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)[0:3]\n",
    "    for word, score in top_scores:\n",
    "        print(word)\n",
    "    \n",
    "    # print 5 random words (for comparison)\n",
    "    print('\\n' + 'RANDOM WORDS:')\n",
    "    random_words = np.random.choice(list(word_scores.keys()), size=3, replace=False)\n",
    "    for word in random_words:\n",
    "        print(word)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two former illini starting lineup miami heat tonight nunn leonard\n",
      "ESTP\n",
      "\n",
      "TOP SCORING WORDS:\n",
      "people\n",
      "think\n",
      "time\n",
      "\n",
      "RANDOM WORDS:\n",
      "react\n",
      "attitudes\n",
      "figured\n"
     ]
    }
   ],
   "source": [
    "summarize(120000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letters(s):\n",
    "    return re.sub('[^a-zA-Z]+', \" \", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti['Cleaned_Text_No_Emoticon'] = df_mbti['Text'].apply(lambda x: letters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valli\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "gram = [row.split() for row in df_mbti.loc[:, 'Cleaned_Text_No_Emoticon']]\n",
    "bigram_phrases = Phrases(gram, min_count=10, progress_per=10000)\n",
    "trigram_phrases = Phrases(bigram_phrases[gram], min_count=1, progress_per=10000)\n",
    "bigram = Phraser(bigram_phrases)\n",
    "trigram = Phraser(trigram_phrases)\n",
    "sentences_b = bigram[gram]\n",
    "sentences_t = trigram[gram]\n",
    "df_mbti[\"Bigram\"] = sentences_b\n",
    "df_mbti['Bigram'] = [','.join(map(str, l)).replace(\",\", \" \") for l in df_mbti['Bigram']]\n",
    "\n",
    "df_mbti[\"Trigram\"] = sentences_t\n",
    "df_mbti['Trigram'] = [','.join(map(str, l)).replace(\",\", \" \") for l in df_mbti['Trigram']]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Text</th>\n",
       "      <th>Reddit</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Typology</th>\n",
       "      <th>Kaggle</th>\n",
       "      <th>Emoticons count</th>\n",
       "      <th>Text_stemmed</th>\n",
       "      <th>Cleaned_Text_No_Emoticon</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Trigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>memeincorrect quote sure trying keep peace family</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>memeincorrect quot sure tri peac famili</td>\n",
       "      <td>memeincorrect quote sure trying keep peace family</td>\n",
       "      <td>memeincorrect quote sure trying keep_peace family</td>\n",
       "      <td>memeincorrect quote sure trying keep_peace family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>memefour distinct flavors nt</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>memefour distinct flavor</td>\n",
       "      <td>memefour distinct flavors nt</td>\n",
       "      <td>memefour distinct flavors nt</td>\n",
       "      <td>memefour distinct flavors nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>memethis definitely intp looks like</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>memethi definit intp look like</td>\n",
       "      <td>memethis definitely intp looks like</td>\n",
       "      <td>memethis definitely intp looks_like</td>\n",
       "      <td>memethis definitely intp looks_like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>theory questionwhat type admire</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>theori questionwhat type admir</td>\n",
       "      <td>theory questionwhat type admire</td>\n",
       "      <td>theory_questionwhat type admire</td>\n",
       "      <td>theory_questionwhat type admire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>memeistj x enfp real</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>memeistj enfp real</td>\n",
       "      <td>memeistj x enfp real</td>\n",
       "      <td>memeistj x enfp real</td>\n",
       "      <td>memeistj x enfp real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214114</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>always think cats fi doms reason websites beco...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>think cat dom reason websit nazi perci nerd le...</td>\n",
       "      <td>always think cats fi doms reason websites beco...</td>\n",
       "      <td>always think cats fi_doms reason websites beco...</td>\n",
       "      <td>always think cats fi_doms reason websites beco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214115</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>soif thread already exists someplace else heck...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>soif thread exist someplac heck delet hereooop...</td>\n",
       "      <td>soif thread already exists someplace else heck...</td>\n",
       "      <td>soif thread already_exists someplace else heck...</td>\n",
       "      <td>soif thread already_exists someplace_else heck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214116</th>\n",
       "      <td>INTP</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>question thing purpl pill pick win lotteri num...</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214117</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>conflict right come want children honest mater...</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214118</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>long personalitycaf chang good like usual turn...</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127583 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag                                               Text  Reddit  \\\n",
       "1       ENFJ  memeincorrect quote sure trying keep peace family       1   \n",
       "3       ENTP                       memefour distinct flavors nt       1   \n",
       "6       ENTP                memethis definitely intp looks like       1   \n",
       "7       ISFJ                    theory questionwhat type admire       1   \n",
       "8       ISTJ                               memeistj x enfp real       1   \n",
       "...      ...                                                ...     ...   \n",
       "214114  ISFP  always think cats fi doms reason websites beco...       0   \n",
       "214115  ENFP  soif thread already exists someplace else heck...       0   \n",
       "214116  INTP  many questions things would take purple pill p...       0   \n",
       "214117  INFP  conflicted right comes wanting children honest...       0   \n",
       "214118  INFP  long since personalitycafe although seem chang...       0   \n",
       "\n",
       "        Twitter  Typology  Kaggle  Emoticons count  \\\n",
       "1             0         0       0                1   \n",
       "3             0         0       0                0   \n",
       "6             0         0       0                0   \n",
       "7             0         0       0                0   \n",
       "8             0         0       0                0   \n",
       "...         ...       ...     ...              ...   \n",
       "214114        0         0       1               13   \n",
       "214115        0         0       1               22   \n",
       "214116        0         0       1                2   \n",
       "214117        0         0       1                1   \n",
       "214118        0         0       1               13   \n",
       "\n",
       "                                             Text_stemmed  \\\n",
       "1                 memeincorrect quot sure tri peac famili   \n",
       "3                                memefour distinct flavor   \n",
       "6                          memethi definit intp look like   \n",
       "7                          theori questionwhat type admir   \n",
       "8                                      memeistj enfp real   \n",
       "...                                                   ...   \n",
       "214114  think cat dom reason websit nazi perci nerd le...   \n",
       "214115  soif thread exist someplac heck delet hereooop...   \n",
       "214116  question thing purpl pill pick win lotteri num...   \n",
       "214117  conflict right come want children honest mater...   \n",
       "214118  long personalitycaf chang good like usual turn...   \n",
       "\n",
       "                                 Cleaned_Text_No_Emoticon  \\\n",
       "1       memeincorrect quote sure trying keep peace family   \n",
       "3                            memefour distinct flavors nt   \n",
       "6                     memethis definitely intp looks like   \n",
       "7                         theory questionwhat type admire   \n",
       "8                                    memeistj x enfp real   \n",
       "...                                                   ...   \n",
       "214114  always think cats fi doms reason websites beco...   \n",
       "214115  soif thread already exists someplace else heck...   \n",
       "214116  many questions things would take purple pill p...   \n",
       "214117  conflicted right comes wanting children honest...   \n",
       "214118  long since personalitycafe although seem chang...   \n",
       "\n",
       "                                                   Bigram  \\\n",
       "1       memeincorrect quote sure trying keep_peace family   \n",
       "3                            memefour distinct flavors nt   \n",
       "6                     memethis definitely intp looks_like   \n",
       "7                         theory_questionwhat type admire   \n",
       "8                                    memeistj x enfp real   \n",
       "...                                                   ...   \n",
       "214114  always think cats fi_doms reason websites beco...   \n",
       "214115  soif thread already_exists someplace else heck...   \n",
       "214116  many questions things would take purple pill p...   \n",
       "214117  conflicted right comes wanting children honest...   \n",
       "214118  long since personalitycafe although seem chang...   \n",
       "\n",
       "                                                  Trigram  \n",
       "1       memeincorrect quote sure trying keep_peace family  \n",
       "3                            memefour distinct flavors nt  \n",
       "6                     memethis definitely intp looks_like  \n",
       "7                         theory_questionwhat type admire  \n",
       "8                                    memeistj x enfp real  \n",
       "...                                                   ...  \n",
       "214114  always think cats fi_doms reason websites beco...  \n",
       "214115  soif thread already_exists someplace_else heck...  \n",
       "214116  many questions things would take purple pill p...  \n",
       "214117  conflicted right comes wanting children honest...  \n",
       "214118  long since personalitycafe although seem chang...  \n",
       "\n",
       "[127583 rows x 11 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mbti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti = df_mbti[[\"Tag\", \"Text\", \"Cleaned_Text_No_Emoticon\", \"Text_stemmed\", \"Bigram\", \"Trigram\", \"Emoticons count\", \"Reddit\", \"Twitter\", \"Typology\", \"Kaggle\"]]\n",
    "df_mbti.columns = [\"Tag\", \"Cleaned_Text\", \"Cleaned_Text_No_Emoticon\", \"Text_stemmed\", \"Bigram\", \"Trigram\", \"Emoticons_count\", \"Reddit\", \"Twitter\", \"Typology\", \"Kaggle\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Cleaned_Text_No_Emoticon</th>\n",
       "      <th>Text_stemmed</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Trigram</th>\n",
       "      <th>Emoticons_count</th>\n",
       "      <th>Reddit</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Typology</th>\n",
       "      <th>Kaggle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>memeincorrect quote sure trying keep peace family</td>\n",
       "      <td>memeincorrect quote sure trying keep peace family</td>\n",
       "      <td>memeincorrect quot sure tri peac famili</td>\n",
       "      <td>memeincorrect quote sure trying keep_peace family</td>\n",
       "      <td>memeincorrect quote sure trying keep_peace family</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>memefour distinct flavors nt</td>\n",
       "      <td>memefour distinct flavors nt</td>\n",
       "      <td>memefour distinct flavor</td>\n",
       "      <td>memefour distinct flavors nt</td>\n",
       "      <td>memefour distinct flavors nt</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>memethis definitely intp looks like</td>\n",
       "      <td>memethis definitely intp looks like</td>\n",
       "      <td>memethi definit intp look like</td>\n",
       "      <td>memethis definitely intp looks_like</td>\n",
       "      <td>memethis definitely intp looks_like</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>theory questionwhat type admire</td>\n",
       "      <td>theory questionwhat type admire</td>\n",
       "      <td>theori questionwhat type admir</td>\n",
       "      <td>theory_questionwhat type admire</td>\n",
       "      <td>theory_questionwhat type admire</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>memeistj x enfp real</td>\n",
       "      <td>memeistj x enfp real</td>\n",
       "      <td>memeistj enfp real</td>\n",
       "      <td>memeistj x enfp real</td>\n",
       "      <td>memeistj x enfp real</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214114</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>always think cats fi doms reason websites beco...</td>\n",
       "      <td>always think cats fi doms reason websites beco...</td>\n",
       "      <td>think cat dom reason websit nazi perci nerd le...</td>\n",
       "      <td>always think cats fi_doms reason websites beco...</td>\n",
       "      <td>always think cats fi_doms reason websites beco...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214115</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>soif thread already exists someplace else heck...</td>\n",
       "      <td>soif thread already exists someplace else heck...</td>\n",
       "      <td>soif thread exist someplac heck delet hereooop...</td>\n",
       "      <td>soif thread already_exists someplace else heck...</td>\n",
       "      <td>soif thread already_exists someplace_else heck...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214116</th>\n",
       "      <td>INTP</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>question thing purpl pill pick win lotteri num...</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214117</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>conflict right come want children honest mater...</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214118</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>long personalitycaf chang good like usual turn...</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127583 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag                                       Cleaned_Text  \\\n",
       "1       ENFJ  memeincorrect quote sure trying keep peace family   \n",
       "3       ENTP                       memefour distinct flavors nt   \n",
       "6       ENTP                memethis definitely intp looks like   \n",
       "7       ISFJ                    theory questionwhat type admire   \n",
       "8       ISTJ                               memeistj x enfp real   \n",
       "...      ...                                                ...   \n",
       "214114  ISFP  always think cats fi doms reason websites beco...   \n",
       "214115  ENFP  soif thread already exists someplace else heck...   \n",
       "214116  INTP  many questions things would take purple pill p...   \n",
       "214117  INFP  conflicted right comes wanting children honest...   \n",
       "214118  INFP  long since personalitycafe although seem chang...   \n",
       "\n",
       "                                 Cleaned_Text_No_Emoticon  \\\n",
       "1       memeincorrect quote sure trying keep peace family   \n",
       "3                            memefour distinct flavors nt   \n",
       "6                     memethis definitely intp looks like   \n",
       "7                         theory questionwhat type admire   \n",
       "8                                    memeistj x enfp real   \n",
       "...                                                   ...   \n",
       "214114  always think cats fi doms reason websites beco...   \n",
       "214115  soif thread already exists someplace else heck...   \n",
       "214116  many questions things would take purple pill p...   \n",
       "214117  conflicted right comes wanting children honest...   \n",
       "214118  long since personalitycafe although seem chang...   \n",
       "\n",
       "                                             Text_stemmed  \\\n",
       "1                 memeincorrect quot sure tri peac famili   \n",
       "3                                memefour distinct flavor   \n",
       "6                          memethi definit intp look like   \n",
       "7                          theori questionwhat type admir   \n",
       "8                                      memeistj enfp real   \n",
       "...                                                   ...   \n",
       "214114  think cat dom reason websit nazi perci nerd le...   \n",
       "214115  soif thread exist someplac heck delet hereooop...   \n",
       "214116  question thing purpl pill pick win lotteri num...   \n",
       "214117  conflict right come want children honest mater...   \n",
       "214118  long personalitycaf chang good like usual turn...   \n",
       "\n",
       "                                                   Bigram  \\\n",
       "1       memeincorrect quote sure trying keep_peace family   \n",
       "3                            memefour distinct flavors nt   \n",
       "6                     memethis definitely intp looks_like   \n",
       "7                         theory_questionwhat type admire   \n",
       "8                                    memeistj x enfp real   \n",
       "...                                                   ...   \n",
       "214114  always think cats fi_doms reason websites beco...   \n",
       "214115  soif thread already_exists someplace else heck...   \n",
       "214116  many questions things would take purple pill p...   \n",
       "214117  conflicted right comes wanting children honest...   \n",
       "214118  long since personalitycafe although seem chang...   \n",
       "\n",
       "                                                  Trigram  Emoticons_count  \\\n",
       "1       memeincorrect quote sure trying keep_peace family                1   \n",
       "3                            memefour distinct flavors nt                0   \n",
       "6                     memethis definitely intp looks_like                0   \n",
       "7                         theory_questionwhat type admire                0   \n",
       "8                                    memeistj x enfp real                0   \n",
       "...                                                   ...              ...   \n",
       "214114  always think cats fi_doms reason websites beco...               13   \n",
       "214115  soif thread already_exists someplace_else heck...               22   \n",
       "214116  many questions things would take purple pill p...                2   \n",
       "214117  conflicted right comes wanting children honest...                1   \n",
       "214118  long since personalitycafe although seem chang...               13   \n",
       "\n",
       "        Reddit  Twitter  Typology  Kaggle  \n",
       "1            1        0         0       0  \n",
       "3            1        0         0       0  \n",
       "6            1        0         0       0  \n",
       "7            1        0         0       0  \n",
       "8            1        0         0       0  \n",
       "...        ...      ...       ...     ...  \n",
       "214114       0        0         0       1  \n",
       "214115       0        0         0       1  \n",
       "214116       0        0         0       1  \n",
       "214117       0        0         0       1  \n",
       "214118       0        0         0       1  \n",
       "\n",
       "[127583 rows x 11 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mbti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.rename(columns={\"Text\": \"Cleaned_Text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.to_csv(\"raw_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>num_noun</th>\n",
       "      <th>num_adj</th>\n",
       "      <th>num_prep</th>\n",
       "      <th>num_det</th>\n",
       "      <th>num_pron</th>\n",
       "      <th>num_verb</th>\n",
       "      <th>num_adverb</th>\n",
       "      <th>num_interject</th>\n",
       "      <th>...</th>\n",
       "      <th>conjunction</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>preposition</th>\n",
       "      <th>nominalization</th>\n",
       "      <th>pronoun.1</th>\n",
       "      <th>interrogative</th>\n",
       "      <th>article</th>\n",
       "      <th>subordination</th>\n",
       "      <th>conjunction.1</th>\n",
       "      <th>preposition.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>memeincorrect quote sure trying keep peace family</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>memefour distinct flavors nt</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>memethis definitely intp looks like</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>theory questionwhat type admire</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>memeistj x enfp real</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151891</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>always think cats fi doms reason websites beco...</td>\n",
       "      <td>191</td>\n",
       "      <td>74</td>\n",
       "      <td>93</td>\n",
       "      <td>69</td>\n",
       "      <td>95</td>\n",
       "      <td>185</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151892</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>soif thread already exists someplace else heck...</td>\n",
       "      <td>314</td>\n",
       "      <td>91</td>\n",
       "      <td>116</td>\n",
       "      <td>91</td>\n",
       "      <td>201</td>\n",
       "      <td>329</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151893</th>\n",
       "      <td>INTP</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>256</td>\n",
       "      <td>69</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>125</td>\n",
       "      <td>210</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151894</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>323</td>\n",
       "      <td>113</td>\n",
       "      <td>218</td>\n",
       "      <td>137</td>\n",
       "      <td>253</td>\n",
       "      <td>398</td>\n",
       "      <td>183</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151895</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>249</td>\n",
       "      <td>92</td>\n",
       "      <td>116</td>\n",
       "      <td>97</td>\n",
       "      <td>210</td>\n",
       "      <td>325</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151896 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag                                       Cleaned_Text  num_noun  \\\n",
       "0       ENFJ  memeincorrect quote sure trying keep peace family         6   \n",
       "1       ENTP                       memefour distinct flavors nt         4   \n",
       "2       ENTP                memethis definitely intp looks like         2   \n",
       "3       ISFJ                    theory questionwhat type admire         3   \n",
       "4       ISTJ                               memeistj x enfp real         6   \n",
       "...      ...                                                ...       ...   \n",
       "151891  ISFP  always think cats fi doms reason websites beco...       191   \n",
       "151892  ENFP  soif thread already exists someplace else heck...       314   \n",
       "151893  INTP  many questions things would take purple pill p...       256   \n",
       "151894  INFP  conflicted right comes wanting children honest...       323   \n",
       "151895  INFP  long since personalitycafe although seem chang...       249   \n",
       "\n",
       "        num_adj  num_prep  num_det  num_pron  num_verb  num_adverb  \\\n",
       "0             1         1        1         2         2           2   \n",
       "1             0         1        0         0         0           0   \n",
       "2             0         1        0         1         2           1   \n",
       "3             0         0        1         1         2           0   \n",
       "4             1         0        0         0         0           0   \n",
       "...         ...       ...      ...       ...       ...         ...   \n",
       "151891       74        93       69        95       185          64   \n",
       "151892       91       116       91       201       329         112   \n",
       "151893       69        88       80       125       210          61   \n",
       "151894      113       218      137       253       398         183   \n",
       "151895       92       116       97       210       325         140   \n",
       "\n",
       "        num_interject  ...  conjunction  pronoun  preposition  nominalization  \\\n",
       "0                   0  ...          0.0      2.0          2.0             0.0   \n",
       "1                   0  ...          0.0      0.0          1.0             0.0   \n",
       "2                   0  ...          0.0      0.0          1.0             0.0   \n",
       "3                   0  ...          1.0      1.0          0.0             0.0   \n",
       "4                   0  ...          0.0      0.0          0.0             0.0   \n",
       "...               ...  ...          ...      ...          ...             ...   \n",
       "151891              1  ...         26.0    129.0         93.0             7.0   \n",
       "151892              0  ...         75.0    251.0        140.0             8.0   \n",
       "151893              1  ...         32.0    155.0         96.0             9.0   \n",
       "151894              3  ...         63.0    300.0        216.0            13.0   \n",
       "151895              0  ...         60.0    259.0        153.0             9.0   \n",
       "\n",
       "        pronoun.1  interrogative  article  subordination  conjunction.1  \\\n",
       "0             0.0            0.0      0.0            0.0            0.0   \n",
       "1             0.0            0.0      0.0            0.0            0.0   \n",
       "2             0.0            0.0      0.0            0.0            0.0   \n",
       "3             0.0            0.0      0.0            0.0            0.0   \n",
       "4             0.0            0.0      0.0            0.0            0.0   \n",
       "...           ...            ...      ...            ...            ...   \n",
       "151891        0.0            0.0      0.0            0.0            0.0   \n",
       "151892        0.0            0.0      0.0            0.0            0.0   \n",
       "151893        0.0            0.0      0.0            0.0            0.0   \n",
       "151894        0.0            0.0      0.0            0.0            0.0   \n",
       "151895        0.0            0.0      0.0            0.0            0.0   \n",
       "\n",
       "        preposition.1  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "151891            0.0  \n",
       "151892            0.0  \n",
       "151893            0.0  \n",
       "151894            0.0  \n",
       "151895            0.0  \n",
       "\n",
       "[151896 rows x 55 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbti.to_csv(\"MBTI.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building corpus using word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "w2v_model = Word2Vec(min_count=10,\n",
    "                     window=3,\n",
    "                     size=15,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.05, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(sentences, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6983770, 12552250)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=5, report_delay=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"yes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "us2gb = {'accessorize': 'accessorise', 'accessorized': 'accessorised', 'accessorizes': 'accessorises', 'accessorizing': 'accessorising',\n",
    " 'acclimatization': 'acclimatisation','acclimatize': 'acclimatise','acclimatized': 'acclimatised','acclimatizes': 'acclimatises','acclimatizing': 'acclimatising',\n",
    " 'accouterments': 'accoutrements','aerogram': 'aerogramme','aerograms': 'aerogrammes','aggrandizement': 'aggrandisement',\n",
    " 'aging': 'ageing','agonize': 'agonise','agonized': 'agonised','agonizes': 'agonises','agonizing': 'agonising',\n",
    " 'agonizingly': 'agonisingly','airplane': 'aeroplane','airplanes ': 'aeroplanes ','almanac': 'almanack','almanacs': 'almanacks','aluminum': 'aluminium',\n",
    " 'amortizable': 'amortisable','amortization': 'amortisation','amortizations': 'amortisations','amortize': 'amortise',\n",
    " 'amortized': 'amortised','amortizes': 'amortises','amortizing': 'amortising','amphitheater': 'amphitheatre',\n",
    " 'amphitheaters': 'amphitheatres','analog': 'analogue','analogs': 'analogues','analyze': 'analyse','analyzed': 'analysed',\n",
    " 'analyzes': 'analyses','analyzing': 'analysing','anemia': 'anaemia','anemic': 'anaemic','anesthesia': 'anaesthesia',\n",
    " 'anesthetic': 'anaesthetic','anesthetics': 'anaesthetics','anesthetist': 'anaesthetist','anesthetists': 'anaesthetists','anesthetize': 'anaesthetize',\n",
    " 'anesthetized': 'anaesthetized','anesthetizes': 'anaesthetizes','anesthetizing': 'anaesthetizing','anglicize': 'anglicise',\n",
    " 'anglicized': 'anglicised','anglicizes': 'anglicises','anglicizing': 'anglicising','annualized': 'annualised',\n",
    " 'antagonize': 'antagonise','antagonized': 'antagonised','antagonizes': 'antagonises','antagonizing': 'antagonising',\n",
    " 'apologize': 'apologise','apologized': 'apologised','apologizes': 'apologises','apologizing': 'apologising',\n",
    " 'appall': 'appal','appalls': 'appals','appetizer': 'appetiser','appetizers': 'appetisers','appetizing': 'appetising',\n",
    " 'appetizingly': 'appetisingly','arbor': 'arbour','arbors': 'arbours','archeological': 'archaeological','archeologically': 'archaeologically',\n",
    " 'archeologist': 'archaeologist','archeologists': 'archaeologists','archeology': 'archaeology','ardor': 'ardour',\n",
    " 'armor': 'armour','armored': 'armoured','armorer': 'armourer','armorers': 'armourers','armories': 'armouries','armory': 'armoury',\n",
    " 'artifact': 'artefact',\n",
    " 'artifacts': 'artefacts',\n",
    " 'authorize': 'authorise',\n",
    " 'authorized': 'authorised',\n",
    " 'authorizes': 'authorises',\n",
    " 'authorizing': 'authorising',\n",
    " 'ax': 'axe',\n",
    " 'backpedaled': 'backpedalled',\n",
    " 'backpedaling': 'backpedalling',\n",
    " 'balk': 'baulk',\n",
    " 'balked': 'baulked',\n",
    " 'balking': 'baulking',\n",
    " 'balks': 'baulks',\n",
    " 'banister': 'bannister',\n",
    " 'banisters': 'bannisters',\n",
    " 'baptize': 'baptise',\n",
    " 'baptized': 'baptised',\n",
    " 'baptizes': 'baptises',\n",
    " 'baptizing': 'baptising',\n",
    " 'bastardize': 'bastardise',\n",
    " 'bastardized': 'bastardised',\n",
    " 'bastardizes': 'bastardises',\n",
    " 'bastardizing': 'bastardising',\n",
    " 'battleax': 'battleaxe',\n",
    " 'bedeviled': 'bedevilled',\n",
    " 'bedeviling': 'bedevilling',\n",
    " 'behavior': 'behaviour',\n",
    " 'behavioral': 'behavioural',\n",
    " 'behaviorism': 'behaviourism',\n",
    " 'behaviorist': 'behaviourist',\n",
    " 'behaviorists': 'behaviourists',\n",
    " 'behaviors': 'behaviours',\n",
    " 'behoove': 'behove',\n",
    " 'behooved': 'behoved',\n",
    " 'behooves': 'behoves',\n",
    " 'bejeweled': 'bejewelled',\n",
    " 'belabor': 'belabour',\n",
    " 'belabored': 'belaboured',\n",
    " 'belaboring': 'belabouring',\n",
    " 'belabors': 'belabours',\n",
    " 'beveled': 'bevelled',\n",
    " 'bevies': 'bevvies',\n",
    " 'bevy': 'bevvy',\n",
    " 'biased': 'biassed',\n",
    " 'biasing': 'biassing',\n",
    " 'binging': 'bingeing',\n",
    " 'bougainvillea': 'bougainvillaea',\n",
    " 'bougainvilleas': 'bougainvillaeas',\n",
    " 'bowdlerize': 'bowdlerise',\n",
    " 'bowdlerized': 'bowdlerised',\n",
    " 'bowdlerizes': 'bowdlerises',\n",
    " 'bowdlerizing': 'bowdlerising',\n",
    " 'breathalyze': 'breathalyse',\n",
    " 'breathalyzed': 'breathalysed',\n",
    " 'breathalyzer': 'breathalyser',\n",
    " 'breathalyzers': 'breathalysers',\n",
    " 'breathalyzes': 'breathalyses',\n",
    " 'breathalyzing': 'breathalysing',\n",
    " 'brutalize': 'brutalise',\n",
    " 'brutalized': 'brutalised',\n",
    " 'brutalizes': 'brutalises',\n",
    " 'brutalizing': 'brutalising',\n",
    " 'busses': 'buses',\n",
    " 'bussing': 'busing',\n",
    " 'caliber': 'calibre',\n",
    " 'calibers': 'calibres',\n",
    " 'caliper': 'calliper',\n",
    " 'calipers': 'callipers',\n",
    " 'calisthenics': 'callisthenics',\n",
    " 'canalize': 'canalise',\n",
    " 'canalized': 'canalised',\n",
    " 'canalizes': 'canalises',\n",
    " 'canalizing': 'canalising',\n",
    " 'cancelation': 'cancellation',\n",
    " 'cancelations': 'cancellations',\n",
    " 'canceled': 'cancelled',\n",
    " 'canceling': 'cancelling',\n",
    " 'candor': 'candour',\n",
    " 'cannibalize': 'cannibalise',\n",
    " 'cannibalized': 'cannibalised',\n",
    " 'cannibalizes': 'cannibalises',\n",
    " 'cannibalizing': 'cannibalising',\n",
    " 'canonize': 'canonise',\n",
    " 'canonized': 'canonised',\n",
    " 'canonizes': 'canonises',\n",
    " 'canonizing': 'canonising',\n",
    " 'capitalize': 'capitalise',\n",
    " 'capitalized': 'capitalised',\n",
    " 'capitalizes': 'capitalises',\n",
    " 'capitalizing': 'capitalising',\n",
    " 'caramelize': 'caramelise',\n",
    " 'caramelized': 'caramelised',\n",
    " 'caramelizes': 'caramelises',\n",
    " 'caramelizing': 'caramelising',\n",
    " 'carbonize': 'carbonise',\n",
    " 'carbonized': 'carbonised',\n",
    " 'carbonizes': 'carbonises',\n",
    " 'carbonizing': 'carbonising',\n",
    " 'caroled': 'carolled',\n",
    " 'caroling': 'carolling',\n",
    " 'catalog': 'catalogue',\n",
    " 'cataloged': 'catalogued',\n",
    " 'cataloging': 'cataloguing',\n",
    " 'catalogs': 'catalogues',\n",
    " 'catalyze': 'catalyse',\n",
    " 'catalyzed': 'catalysed',\n",
    " 'catalyzes': 'catalyses',\n",
    " 'catalyzing': 'catalysing',\n",
    " 'categorize': 'categorise',\n",
    " 'categorized': 'categorised',\n",
    " 'categorizes': 'categorises',\n",
    " 'categorizing': 'categorising',\n",
    " 'cauterize': 'cauterise',\n",
    " 'cauterized': 'cauterised',\n",
    " 'cauterizes': 'cauterises',\n",
    " 'cauterizing': 'cauterising',\n",
    " 'caviled': 'cavilled',\n",
    " 'caviling': 'cavilling',\n",
    " 'center': 'centre',\n",
    " 'centered': 'centred',\n",
    " 'centerfold': 'centrefold',\n",
    " 'centerfolds': 'centrefolds',\n",
    " 'centerpiece': 'centrepiece',\n",
    " 'centerpieces': 'centrepieces',\n",
    " 'centers': 'centres',\n",
    " 'centigram': 'centigramme',\n",
    " 'centigrams': 'centigrammes',\n",
    " 'centiliter': 'centilitre',\n",
    " 'centiliters': 'centilitres',\n",
    " 'centimeter': 'centimetre',\n",
    " 'centimeters': 'centimetres',\n",
    " 'centralize': 'centralise',\n",
    " 'centralized': 'centralised',\n",
    " 'centralizes': 'centralises',\n",
    " 'centralizing': 'centralising',\n",
    " 'cesarean': 'caesarean',\n",
    " 'cesareans': 'caesareans',\n",
    " 'channeled': 'channelled',\n",
    " 'channeling': 'channelling',\n",
    " 'characterize': 'characterise',\n",
    " 'characterized': 'characterised',\n",
    " 'characterizes': 'characterises',\n",
    " 'characterizing': 'characterising',\n",
    " 'check': 'cheque',\n",
    " 'checkbook': 'chequebook',\n",
    " 'checkbooks': 'chequebooks',\n",
    " 'checkered': 'chequered',\n",
    " 'checks': 'cheques',\n",
    " 'chili': 'chilli',\n",
    " 'chimera': 'chimaera',\n",
    " 'chimeras': 'chimaeras',\n",
    " 'chiseled': 'chiselled',\n",
    " 'chiseling': 'chiselling',\n",
    " 'cipher': 'cypher',\n",
    " 'ciphers': 'cyphers',\n",
    " 'circularize': 'circularise',\n",
    " 'circularized': 'circularised',\n",
    " 'circularizes': 'circularises',\n",
    " 'circularizing': 'circularising',\n",
    " 'civilize': 'civilise',\n",
    " 'civilized': 'civilised',\n",
    " 'civilizes': 'civilises',\n",
    " 'civilizing': 'civilising',\n",
    " 'clamor': 'clamour',\n",
    " 'clamored': 'clamoured',\n",
    " 'clamoring': 'clamouring',\n",
    " 'clamors': 'clamours',\n",
    " 'clangor': 'clangour',\n",
    " 'clarinetist': 'clarinettist',\n",
    " 'clarinetists': 'clarinettists',\n",
    " 'collectivize': 'collectivise',\n",
    " 'collectivized': 'collectivised',\n",
    " 'collectivizes': 'collectivises',\n",
    " 'collectivizing': 'collectivising',\n",
    " 'colonization': 'colonisation',\n",
    " 'colonize': 'colonise',\n",
    " 'colonized': 'colonised',\n",
    " 'colonizer': 'coloniser',\n",
    " 'colonizers': 'colonisers',\n",
    " 'colonizes': 'colonises',\n",
    " 'colonizing': 'colonising',\n",
    " 'color': 'colour',\n",
    " 'colorant': 'colourant',\n",
    " 'colorants': 'colourants',\n",
    " 'colored': 'coloured',\n",
    " 'coloreds': 'coloureds',\n",
    " 'colorful': 'colourful',\n",
    " 'colorfully': 'colourfully',\n",
    " 'coloring': 'colouring',\n",
    " 'colorize': 'colourize',\n",
    " 'colorized': 'colourized',\n",
    " 'colorizes': 'colourizes',\n",
    " 'colorizing': 'colourizing',\n",
    " 'colorless': 'colourless',\n",
    " 'colors': 'colours',\n",
    " 'commercialize': 'commercialise',\n",
    " 'commercialized': 'commercialised',\n",
    " 'commercializes': 'commercialises',\n",
    " 'commercializing': 'commercialising',\n",
    " 'compartmentalize': 'compartmentalise',\n",
    " 'compartmentalized': 'compartmentalised',\n",
    " 'compartmentalizes': 'compartmentalises',\n",
    " 'compartmentalizing': 'compartmentalising',\n",
    " 'computerize': 'computerise',\n",
    " 'computerized': 'computerised',\n",
    " 'computerizes': 'computerises',\n",
    " 'computerizing': 'computerising',\n",
    " 'conceptualize': 'conceptualise',\n",
    " 'conceptualized': 'conceptualised',\n",
    " 'conceptualizes': 'conceptualises',\n",
    " 'conceptualizing': 'conceptualising',\n",
    " 'connection': 'connexion',\n",
    " 'connections': 'connexions',\n",
    " 'contextualize': 'contextualise',\n",
    " 'contextualized': 'contextualised',\n",
    " 'contextualizes': 'contextualises',\n",
    " 'contextualizing': 'contextualising',\n",
    " 'councilor': 'councillor',\n",
    " 'councilors': 'councillors',\n",
    " 'counseled': 'counselled',\n",
    " 'counseling': 'counselling',\n",
    " 'counselor': 'counsellor',\n",
    " 'counselors': 'counsellors',\n",
    " 'cozier': 'cosier',\n",
    " 'cozies': 'cosies',\n",
    " 'coziest': 'cosiest',\n",
    " 'cozily': 'cosily',\n",
    " 'coziness': 'cosiness',\n",
    " 'cozy': 'cosy',\n",
    " 'crenelated': 'crenellated',\n",
    " 'criminalize': 'criminalise',\n",
    " 'criminalized': 'criminalised',\n",
    " 'criminalizes': 'criminalises',\n",
    " 'criminalizing': 'criminalising',\n",
    " 'criticize': 'criticise',\n",
    " 'criticized': 'criticised',\n",
    " 'criticizes': 'criticises',\n",
    " 'criticizing': 'criticising',\n",
    " 'crueler': 'crueller',\n",
    " 'cruelest': 'cruellest',\n",
    " 'crystallization': 'crystallisation',\n",
    " 'crystallize': 'crystallise',\n",
    " 'crystallized': 'crystallised',\n",
    " 'crystallizes': 'crystallises',\n",
    " 'crystallizing': 'crystallising',\n",
    " 'cudgeled': 'cudgelled',\n",
    " 'cudgeling': 'cudgelling',\n",
    " 'customize': 'customise',\n",
    " 'customized': 'customised',\n",
    " 'customizes': 'customises',\n",
    " 'customizing': 'customising',\n",
    " 'decentralization': 'decentralisation',\n",
    " 'decentralize': 'decentralise',\n",
    " 'decentralized': 'decentralised',\n",
    " 'decentralizes': 'decentralises',\n",
    " 'decentralizing': 'decentralising',\n",
    " 'decriminalization': 'decriminalisation',\n",
    " 'decriminalize': 'decriminalise',\n",
    " 'decriminalized': 'decriminalised',\n",
    " 'decriminalizes': 'decriminalises',\n",
    " 'decriminalizing': 'decriminalising',\n",
    " 'defense': 'defence',\n",
    " 'defenseless': 'defenceless',\n",
    " 'defenses': 'defences',\n",
    " 'dehumanization': 'dehumanisation',\n",
    " 'dehumanize': 'dehumanise',\n",
    " 'dehumanized': 'dehumanised',\n",
    " 'dehumanizes': 'dehumanises',\n",
    " 'dehumanizing': 'dehumanising',\n",
    " 'demeanor': 'demeanour',\n",
    " 'demilitarization': 'demilitarisation',\n",
    " 'demilitarize': 'demilitarise',\n",
    " 'demilitarized': 'demilitarised',\n",
    " 'demilitarizes': 'demilitarises',\n",
    " 'demilitarizing': 'demilitarising',\n",
    " 'demobilization': 'demobilisation',\n",
    " 'demobilize': 'demobilise',\n",
    " 'demobilized': 'demobilised',\n",
    " 'demobilizes': 'demobilises',\n",
    " 'demobilizing': 'demobilising',\n",
    " 'democratization': 'democratisation',\n",
    " 'democratize': 'democratise',\n",
    " 'democratized': 'democratised',\n",
    " 'democratizes': 'democratises',\n",
    " 'democratizing': 'democratising',\n",
    " 'demonize': 'demonise',\n",
    " 'demonized': 'demonised',\n",
    " 'demonizes': 'demonises',\n",
    " 'demonizing': 'demonising',\n",
    " 'demoralization': 'demoralisation',\n",
    " 'demoralize': 'demoralise',\n",
    " 'demoralized': 'demoralised',\n",
    " 'demoralizes': 'demoralises',\n",
    " 'demoralizing': 'demoralising',\n",
    " 'denationalization': 'denationalisation',\n",
    " 'denationalize': 'denationalise',\n",
    " 'denationalized': 'denationalised',\n",
    " 'denationalizes': 'denationalises',\n",
    " 'denationalizing': 'denationalising',\n",
    " 'deodorize': 'deodorise',\n",
    " 'deodorized': 'deodorised',\n",
    " 'deodorizes': 'deodorises',\n",
    " 'deodorizing': 'deodorising',\n",
    " 'depersonalize': 'depersonalise',\n",
    " 'depersonalized': 'depersonalised',\n",
    " 'depersonalizes': 'depersonalises',\n",
    " 'depersonalizing': 'depersonalising',\n",
    " 'deputize': 'deputise',\n",
    " 'deputized': 'deputised',\n",
    " 'deputizes': 'deputises',\n",
    " 'deputizing': 'deputising',\n",
    " 'desensitization': 'desensitisation',\n",
    " 'desensitize': 'desensitise',\n",
    " 'desensitized': 'desensitised',\n",
    " 'desensitizes': 'desensitises',\n",
    " 'desensitizing': 'desensitising',\n",
    " 'destabilization': 'destabilisation',\n",
    " 'destabilize': 'destabilise',\n",
    " 'destabilized': 'destabilised',\n",
    " 'destabilizes': 'destabilises',\n",
    " 'destabilizing': 'destabilising',\n",
    " 'dialed': 'dialled',\n",
    " 'dialing': 'dialling',\n",
    " 'dialog': 'dialogue',\n",
    " 'dialogs': 'dialogues',\n",
    " 'diarrhea': 'diarrhoea',\n",
    " 'digitize': 'digitise',\n",
    " 'digitized': 'digitised',\n",
    " 'digitizes': 'digitises',\n",
    " 'digitizing': 'digitising',\n",
    " 'discolor': 'discolour',\n",
    " 'discolored': 'discoloured',\n",
    " 'discoloring': 'discolouring',\n",
    " 'discolors': 'discolours',\n",
    " 'disemboweled': 'disembowelled',\n",
    " 'disemboweling': 'disembowelling',\n",
    " 'disfavor': 'disfavour',\n",
    " 'disheveled': 'dishevelled',\n",
    " 'passivizes': 'passivises',\n",
    " 'passivizing': 'passivising',\n",
    " 'pasteurization': 'pasteurisation',\n",
    " 'pasteurize': 'pasteurise',\n",
    " 'pasteurized': 'pasteurised',\n",
    " 'pasteurizes': 'pasteurises',\n",
    " 'pasteurizing': 'pasteurising',\n",
    " 'patronize': 'patronise',\n",
    " 'patronized': 'patronised',\n",
    " 'patronizes': 'patronises',\n",
    " 'patronizing': 'patronising',\n",
    " 'patronizingly': 'patronisingly',\n",
    " 'pedaled': 'pedalled',\n",
    " 'pedaling': 'pedalling',\n",
    " 'pederast': 'paederast',\n",
    " 'pederasts': 'paederasts',\n",
    " 'pedestrianization': 'pedestrianisation',\n",
    " 'pedestrianize': 'pedestrianise',\n",
    " 'pedestrianized': 'pedestrianised',\n",
    " 'pedestrianizes': 'pedestrianises',\n",
    " 'pedestrianizing': 'pedestrianising',\n",
    " 'pediatric': 'paediatric',\n",
    " 'pediatrician': 'paediatrician',\n",
    " 'pediatricians': 'paediatricians',\n",
    " 'pediatrics': 'paediatrics',\n",
    " 'pedophile': 'paedophile',\n",
    " 'pedophiles': 'paedophiles',\n",
    " 'pedophilia': 'paedophilia',\n",
    " 'penalize': 'penalise',\n",
    " 'penalized': 'penalised',\n",
    " 'penalizes': 'penalises',\n",
    " 'penalizing': 'penalising',\n",
    " 'penciled': 'pencilled',\n",
    " 'penciling': 'pencilling',\n",
    " 'personalize': 'personalise',\n",
    " 'personalized': 'personalised',\n",
    " 'personalizes': 'personalises',\n",
    " 'personalizing': 'personalising',\n",
    " 'pharmacopeia': 'pharmacopoeia',\n",
    " 'pharmacopeias': 'pharmacopoeias',\n",
    " 'philosophize': 'philosophise',\n",
    " 'philosophized': 'philosophised',\n",
    " 'philosophizes': 'philosophises',\n",
    " 'philosophizing': 'philosophising',\n",
    " 'phony ': 'phoney ',\n",
    " 'pizzazz': 'pzazz',\n",
    " 'plagiarize': 'plagiarise',\n",
    " 'plagiarized': 'plagiarised',\n",
    " 'plagiarizes': 'plagiarises',\n",
    " 'plagiarizing': 'plagiarising',\n",
    " 'plow': 'plough',\n",
    " 'plowed': 'ploughed',\n",
    " 'plowing': 'ploughing',\n",
    " 'plowman': 'ploughman',\n",
    " 'plowmen': 'ploughmen',\n",
    " 'plows': 'ploughs',\n",
    " 'plowshare': 'ploughshare',\n",
    " 'plowshares': 'ploughshares',\n",
    " 'polarization': 'polarisation',\n",
    " 'polarize': 'polarise',\n",
    " 'polarized': 'polarised',\n",
    " 'polarizes': 'polarises',\n",
    " 'polarizing': 'polarising',\n",
    " 'politicization': 'politicisation',\n",
    " 'politicize': 'politicise',\n",
    " 'politicized': 'politicised',\n",
    " 'politicizes': 'politicises',\n",
    " 'politicizing': 'politicising',\n",
    " 'popularization': 'popularisation',\n",
    " 'popularize': 'popularise',\n",
    " 'popularized': 'popularised',\n",
    " 'popularizes': 'popularises',\n",
    " 'popularizing': 'popularising',\n",
    " 'pouf': 'pouffe',\n",
    " 'poufs': 'pouffes',\n",
    " 'practice': 'practise',\n",
    " 'practiced': 'practised',\n",
    " 'practices': 'practises',\n",
    " 'practicing ': 'practising ',\n",
    " 'presidium': 'praesidium',\n",
    " 'presidiums ': 'praesidiums ',\n",
    " 'pressurization': 'pressurisation',\n",
    " 'pressurize': 'pressurise',\n",
    " 'pressurized': 'pressurised',\n",
    " 'pressurizes': 'pressurises',\n",
    " 'pressurizing': 'pressurising',\n",
    " 'pretense': 'pretence',\n",
    " 'pretenses': 'pretences',\n",
    " 'primeval': 'primaeval',\n",
    " 'prioritization': 'prioritisation',\n",
    " 'prioritize': 'prioritise',\n",
    " 'prioritized': 'prioritised',\n",
    " 'prioritizes': 'prioritises',\n",
    " 'prioritizing': 'prioritising',\n",
    " 'privatization': 'privatisation',\n",
    " 'privatizations': 'privatisations',\n",
    " 'privatize': 'privatise',\n",
    " 'privatized': 'privatised',\n",
    " 'privatizes': 'privatises',\n",
    " 'privatizing': 'privatising',\n",
    " 'professionalization': 'professionalisation',\n",
    " 'professionalize': 'professionalise',\n",
    " 'professionalized': 'professionalised',\n",
    " 'professionalizes': 'professionalises',\n",
    " 'professionalizing': 'professionalising',\n",
    " 'program': 'programme',\n",
    " 'programs': 'programmes',\n",
    " 'prolog': 'prologue',\n",
    " 'prologs': 'prologues',\n",
    " 'propagandize': 'propagandise',\n",
    " 'propagandized': 'propagandised',\n",
    " 'propagandizes': 'propagandises',\n",
    " 'propagandizing': 'propagandising',\n",
    " 'proselytize': 'proselytise',\n",
    " 'proselytized': 'proselytised',\n",
    " 'proselytizer': 'proselytiser',\n",
    " 'proselytizers': 'proselytisers',\n",
    " 'proselytizes': 'proselytises',\n",
    " 'proselytizing': 'proselytising',\n",
    " 'psychoanalyze': 'psychoanalyse',\n",
    " 'psychoanalyzed': 'psychoanalysed',\n",
    " 'psychoanalyzes': 'psychoanalyses',\n",
    " 'psychoanalyzing': 'psychoanalysing',\n",
    " 'publicize': 'publicise',\n",
    " 'publicized': 'publicised',\n",
    " 'publicizes': 'publicises',\n",
    " 'publicizing': 'publicising',\n",
    " 'pulverization': 'pulverisation',\n",
    " 'pulverize': 'pulverise',\n",
    " 'pulverized': 'pulverised',\n",
    " 'pulverizes': 'pulverises',\n",
    " 'pulverizing': 'pulverising',\n",
    " 'pummel': 'pummelled',\n",
    " 'pummeled': 'pummelling',\n",
    " 'quarreled': 'quarrelled',\n",
    " 'quarreling': 'quarrelling',\n",
    " 'radicalize': 'radicalise',\n",
    " 'radicalized': 'radicalised',\n",
    " 'radicalizes': 'radicalises',\n",
    " 'radicalizing': 'radicalising',\n",
    " 'rancor': 'rancour',\n",
    " 'randomize': 'randomise',\n",
    " 'randomized': 'randomised',\n",
    " 'randomizes': 'randomises',\n",
    " 'randomizing': 'randomising',\n",
    " 'rationalization': 'rationalisation',\n",
    " 'rationalizations': 'rationalisations',\n",
    " 'rationalize': 'rationalise',\n",
    " 'rationalized': 'rationalised',\n",
    " 'rationalizes': 'rationalises',\n",
    " 'rationalizing': 'rationalising',\n",
    " 'raveled': 'ravelled',\n",
    " 'raveling': 'ravelling',\n",
    " 'realizable': 'realisable',\n",
    " 'realization': 'realisation',\n",
    " 'realizations': 'realisations',\n",
    " 'realize': 'realise',\n",
    " 'realized': 'realised',\n",
    " 'realizes': 'realises',\n",
    " 'realizing': 'realising',\n",
    " 'recognizable': 'recognisable',\n",
    " 'recognizably': 'recognisably',\n",
    " 'recognizance': 'recognisance',\n",
    " 'recognize': 'recognise',\n",
    " 'recognized': 'recognised',\n",
    " 'recognizes': 'recognises',\n",
    " 'recognizing': 'recognising',\n",
    " 'reconnoiter': 'reconnoitre',\n",
    " 'reconnoitered': 'reconnoitred',\n",
    " 'reconnoitering': 'reconnoitring',\n",
    " 'reconnoiters': 'reconnoitres',\n",
    " 'refueled': 'refuelled',\n",
    " 'refueling': 'refuelling',\n",
    " 'regularization': 'regularisation',\n",
    " 'regularize': 'regularise',\n",
    " 'regularized': 'regularised',\n",
    " 'regularizes': 'regularises',\n",
    " 'regularizing': 'regularising',\n",
    " 'remodeled': 'remodelled',\n",
    " 'remodeling': 'remodelling',\n",
    " 'remold': 'remould',\n",
    " 'remolded': 'remoulded',\n",
    " 'remolding': 'remoulding',\n",
    " 'remolds': 'remoulds',\n",
    " 'reorganization': 'reorganisation',\n",
    " 'reorganizations': 'reorganisations',\n",
    " 'reorganize': 'reorganise',\n",
    " 'reorganized': 'reorganised',\n",
    " 'reorganizes': 'reorganises',\n",
    " 'reorganizing': 'reorganising',\n",
    " 'reveled': 'revelled',\n",
    " 'reveler': 'reveller',\n",
    " 'revelers': 'revellers',\n",
    " 'reveling': 'revelling',\n",
    " 'revitalize': 'revitalise',\n",
    " 'revitalized': 'revitalised',\n",
    " 'revitalizes': 'revitalises',\n",
    " 'revitalizing': 'revitalising',\n",
    " 'revolutionize': 'revolutionise',\n",
    " 'revolutionized': 'revolutionised',\n",
    " 'revolutionizes': 'revolutionises',\n",
    " 'revolutionizing': 'revolutionising',\n",
    " 'rhapsodize': 'rhapsodise',\n",
    " 'rhapsodized': 'rhapsodised',\n",
    " 'rhapsodizes': 'rhapsodises',\n",
    " 'rhapsodizing': 'rhapsodising',\n",
    " 'rigor': 'rigour',\n",
    " 'rigors': 'rigours',\n",
    " 'ritualized': 'ritualised',\n",
    " 'rivaled': 'rivalled',\n",
    " 'rivaling': 'rivalling',\n",
    " 'romanticize': 'romanticise',\n",
    " 'romanticized': 'romanticised',\n",
    " 'romanticizes': 'romanticises',\n",
    " 'romanticizing': 'romanticising',\n",
    " 'rumor': 'rumour',\n",
    " 'rumored': 'rumoured',\n",
    " 'rumors': 'rumours',\n",
    " 'saber': 'sabre',\n",
    " 'sabers': 'sabres',\n",
    " 'saltpeter': 'saltpetre',\n",
    " 'sanitize': 'sanitise',\n",
    " 'sanitized': 'sanitised',\n",
    " 'sanitizes': 'sanitises',\n",
    " 'sanitizing': 'sanitising',\n",
    " 'satirize': 'satirise',\n",
    " 'satirized': 'satirised',\n",
    " 'satirizes': 'satirises',\n",
    " 'satirizing': 'satirising',\n",
    " 'savior': 'saviour',\n",
    " 'saviors': 'saviours',\n",
    " 'savor': 'savour',\n",
    " 'savored': 'savoured',\n",
    " 'savories': 'savouries',\n",
    " 'savoring': 'savouring',\n",
    " 'savors': 'savours',\n",
    " 'savory': 'savoury',\n",
    " 'scandalize': 'scandalise',\n",
    " 'scandalized': 'scandalised',\n",
    " 'scandalizes': 'scandalises',\n",
    " 'scandalizing': 'scandalising',\n",
    " 'scepter': 'sceptre',\n",
    " 'scepters': 'sceptres',\n",
    " 'scrutinize': 'scrutinise',\n",
    " 'scrutinized': 'scrutinised',\n",
    " 'scrutinizes': 'scrutinises',\n",
    " 'scrutinizing': 'scrutinising',\n",
    " 'secularization': 'secularisation',\n",
    " 'secularize': 'secularise',\n",
    " 'secularized': 'secularised',\n",
    " 'secularizes': 'secularises',\n",
    " 'secularizing': 'secularising',\n",
    " 'sensationalize': 'sensationalise',\n",
    " 'sensationalized': 'sensationalised',\n",
    " 'sensationalizes': 'sensationalises',\n",
    " 'sensationalizing': 'sensationalising',\n",
    " 'sensitize': 'sensitise',\n",
    " 'sensitized': 'sensitised',\n",
    " 'sensitizes': 'sensitises',\n",
    " 'sensitizing': 'sensitising',\n",
    " 'sentimentalize': 'sentimentalise',\n",
    " 'sentimentalized': 'sentimentalised',\n",
    " 'sentimentalizes': 'sentimentalises',\n",
    " 'sentimentalizing': 'sentimentalising',\n",
    " 'sepulcher': 'sepulchre',\n",
    " 'sepulchers ': 'sepulchres',\n",
    " 'serialization': 'serialisation',\n",
    " 'serializations': 'serialisations',\n",
    " 'serialize': 'serialise',\n",
    " 'serialized': 'serialised',\n",
    " 'serializes': 'serialises',\n",
    " 'serializing': 'serialising',\n",
    " 'sermonize': 'sermonise',\n",
    " 'sermonized': 'sermonised',\n",
    " 'sermonizes': 'sermonises',\n",
    " 'sermonizing': 'sermonising',\n",
    " 'sheik ': 'sheikh ',\n",
    " 'shoveled': 'shovelled',\n",
    " 'shoveling': 'shovelling',\n",
    " 'shriveled': 'shrivelled',\n",
    " 'shriveling': 'shrivelling',\n",
    " 'signaled': 'signalled',\n",
    " 'signaling': 'signalling',\n",
    " 'signalize': 'signalise',\n",
    " 'signalized': 'signalised',\n",
    " 'signalizes': 'signalises',\n",
    " 'signalizing': 'signalising',\n",
    " 'siphon': 'syphon',\n",
    " 'siphoned': 'syphoned',\n",
    " 'siphoning': 'syphoning',\n",
    " 'siphons': 'syphons',\n",
    " 'skeptic': 'sceptic',\n",
    " 'skeptical': 'sceptical',\n",
    " 'skeptically': 'sceptically',\n",
    " 'skepticism': 'scepticism',\n",
    " 'skeptics': 'sceptics',\n",
    " 'smolder': 'smoulder',\n",
    " 'smoldered': 'smouldered',\n",
    " 'smoldering': 'smouldering',\n",
    " 'smolders': 'smoulders',\n",
    " 'sniveled': 'snivelled',\n",
    " 'sniveling': 'snivelling',\n",
    " 'snorkeled': 'snorkelled',\n",
    " 'snorkeling': 'snorkelling',\n",
    " 'snowplow': 'snowploughs',\n",
    " 'socialization': 'socialisation',\n",
    " 'socialize': 'socialise',\n",
    " 'socialized': 'socialised',\n",
    " 'socializes': 'socialises',\n",
    " 'socializing': 'socialising',\n",
    " 'sodomize': 'sodomise',\n",
    " 'sodomized': 'sodomised',\n",
    " 'sodomizes': 'sodomises','sodomizing': 'sodomising','solemnize': 'solemnise','solemnized': 'solemnised',\n",
    " 'solemnizes': 'solemnises','solemnizing': 'solemnising',\n",
    " 'somber': 'sombre','specialization': 'specialisation','specializations': 'specialisations',\n",
    " 'specialize': 'specialise','specialized': 'specialised','specializes': 'specialises','specializing': 'specialising',\n",
    " 'specter': 'spectre','specters': 'spectres','spiraled': 'spiralled',\n",
    " 'spiraling': 'spiralling','splendor': 'splendour','splendors': 'splendours','squirreled': 'squirrelled','squirreling': 'squirrelling',\n",
    " 'stabilization': 'stabilisation','stabilize': 'stabilise','stabilized': 'stabilised','stabilizer': 'stabiliser',\n",
    " 'stabilizers': 'stabilisers','stabilizes': 'stabilises','stabilizing': 'stabilising','standardization': 'standardisation',\n",
    " 'standardize': 'standardise','standardized': 'standardised','standardizes': 'standardises','standardizing': 'standardising',\n",
    " 'stenciled': 'stencilled','stenciling': 'stencilling','sterilization': 'sterilisation','sterilizations': 'sterilisations',\n",
    " 'sterilize': 'sterilise','sterilized': 'sterilised','sterilizer': 'steriliser','sterilizers': 'sterilisers',\n",
    " 'sterilizes': 'sterilises','sterilizing': 'sterilising','stigmatization': 'stigmatisation','stigmatize': 'stigmatise',\n",
    " 'stigmatized': 'stigmatised','stigmatizes': 'stigmatises','stigmatizing': 'stigmatising','stories': 'storeys',\n",
    " 'story': 'storey','subsidization': 'subsidisation','subsidize': 'subsidise','subsidized': 'subsidised',\n",
    " 'subsidizer': 'subsidiser','subsidizers': 'subsidisers','subsidizes': 'subsidises','subsidizing': 'subsidising',\n",
    " 'succor': 'succour','succored': 'succoured','succoring': 'succouring','succors': 'succours','sulfate': 'sulphate',\n",
    " 'sulfates': 'sulphates','sulfide': 'sulphide','sulfides': 'sulphides','sulfur': 'sulphur','sulfurous': 'sulphurous'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valli\\anaconda3\\lib\\site-packages\\texthero\\preprocessing.py:598: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(pattern, r\"\\2 \\3 \\4 \\5\").str.split()\n"
     ]
    }
   ],
   "source": [
    "#Extra\n",
    "df_mbti['Tokens'] = hero.tokenize(df_mbti['Text'])\n",
    "SFW_13['clean_docs'] = SFW_13['prof + knowlg + ability'].apply(lambda x: x.replace('\\n', '. '))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
